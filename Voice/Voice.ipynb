{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Automated ML Pipeline Generator using TPOT in Python\n",
    "---\n",
    "<br/>\n",
    "\n",
    "### What is TPOT?\n",
    "- Tree-Based Pipeline Optimization Tool (TPOT)\n",
    "- a tool that optimizes machine learning pipelines using genetic programming. \n",
    "- exploring thousands of possible pipelines to find the best one for your data. \n",
    "- Once TPOT is finished searching (or you get tired of waiting), it provides you with the Python code for the best pipeline it found so you can tinker with the pipeline from there. \n",
    "- TPOT makes use of the Python-based scikit-learn library as its ML menu.\n",
    "- pipeline is an independently executable workflow of a complete machine learning task.\n",
    "\n",
    "### To install :\n",
    "    pip install tpot\n",
    "\n",
    "### Dependencies :\n",
    "- scikit learn\n",
    "- numpy \n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data_url = \"https://raw.githubusercontent.com/20b2122/AutoML-using-TPOT-in-python/main/Voice/voice.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "0   274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
       "1   634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
       "2  1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
       "3     4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
       "4     4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
       "\n",
       "     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000   male  \n",
       "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632   male  \n",
       "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512   male  \n",
       "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119   male  \n",
       "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274   male  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "meanfreq    0\n",
       "sd          0\n",
       "median      0\n",
       "Q25         0\n",
       "Q75         0\n",
       "IQR         0\n",
       "skew        0\n",
       "kurt        0\n",
       "sp.ent      0\n",
       "sfm         0\n",
       "mode        0\n",
       "centroid    0\n",
       "meanfun     0\n",
       "minfun      0\n",
       "maxfun      0\n",
       "meandom     0\n",
       "mindom      0\n",
       "maxdom      0\n",
       "dfrange     0\n",
       "modindx     0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 21 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   meanfreq  3168 non-null   float64\n",
      " 1   sd        3168 non-null   float64\n",
      " 2   median    3168 non-null   float64\n",
      " 3   Q25       3168 non-null   float64\n",
      " 4   Q75       3168 non-null   float64\n",
      " 5   IQR       3168 non-null   float64\n",
      " 6   skew      3168 non-null   float64\n",
      " 7   kurt      3168 non-null   float64\n",
      " 8   sp.ent    3168 non-null   float64\n",
      " 9   sfm       3168 non-null   float64\n",
      " 10  mode      3168 non-null   float64\n",
      " 11  centroid  3168 non-null   float64\n",
      " 12  meanfun   3168 non-null   float64\n",
      " 13  minfun    3168 non-null   float64\n",
      " 14  maxfun    3168 non-null   float64\n",
      " 15  meandom   3168 non-null   float64\n",
      " 16  mindom    3168 non-null   float64\n",
      " 17  maxdom    3168 non-null   float64\n",
      " 18  dfrange   3168 non-null   float64\n",
      " 19  modindx   3168 non-null   float64\n",
      " 20  label     3168 non-null   object \n",
      "dtypes: float64(20), object(1)\n",
      "memory usage: 519.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convert Categorical (label) to Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['label'] = df['label'].map({'female': 1, 'male': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "0   274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
       "1   634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
       "2  1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
       "3     4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
       "4     4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
       "\n",
       "     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000      0  \n",
       "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632      0  \n",
       "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512      0  \n",
       "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119      0  \n",
       "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274      0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 21 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   meanfreq  3168 non-null   float64\n",
      " 1   sd        3168 non-null   float64\n",
      " 2   median    3168 non-null   float64\n",
      " 3   Q25       3168 non-null   float64\n",
      " 4   Q75       3168 non-null   float64\n",
      " 5   IQR       3168 non-null   float64\n",
      " 6   skew      3168 non-null   float64\n",
      " 7   kurt      3168 non-null   float64\n",
      " 8   sp.ent    3168 non-null   float64\n",
      " 9   sfm       3168 non-null   float64\n",
      " 10  mode      3168 non-null   float64\n",
      " 11  centroid  3168 non-null   float64\n",
      " 12  meanfun   3168 non-null   float64\n",
      " 13  minfun    3168 non-null   float64\n",
      " 14  maxfun    3168 non-null   float64\n",
      " 15  meandom   3168 non-null   float64\n",
      " 16  mindom    3168 non-null   float64\n",
      " 17  maxdom    3168 non-null   float64\n",
      " 18  dfrange   3168 non-null   float64\n",
      " 19  modindx   3168 non-null   float64\n",
      " 20  label     3168 non-null   int64  \n",
      "dtypes: float64(20), int64(1)\n",
      "memory usage: 519.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info() # double check if all of the categorical has been converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Splitting data into input and output (label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = df.iloc[:,:20] # input\n",
    "y = df.iloc[:,20:] # output - label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\tpot\\builtins\\__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    }
   ],
   "source": [
    "import tpot\n",
    "import time # to calculate how long it takes for the TPOT to finish execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the available methods and attributes at TPOT\n",
    "\n",
    "Using this dataset, we will use TPOTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TPOTClassifier',\n",
       " 'TPOTRegressor',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " '_version',\n",
       " 'base',\n",
       " 'builtins',\n",
       " 'config',\n",
       " 'decorators',\n",
       " 'driver',\n",
       " 'export_utils',\n",
       " 'gp_deap',\n",
       " 'gp_types',\n",
       " 'main',\n",
       " 'metrics',\n",
       " 'operator_utils',\n",
       " 'tpot']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tpot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data in x and y into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "\n",
    "# Init\n",
    "tpot = TPOTClassifier(generations=5, population_size=50, verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generation**: Number of iterations to run the pipeline optimization process.TPOT will work better when you give it more generations (and therefore time) to optimize the pipeline. <br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Population Size**: Number of individuals to retain in the GP population every generation.<br/>\n",
    "<br/>\n",
    "TPOT will evaluate POPULATION_SIZE (50) + GENERATIONS (5) x OFFSPRING_SIZE (50) = 300 pipelines in total.\n",
    "<br/>\n",
    "By default, OFFSPRING_SIZE = POPULATION_SIZE<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verbosity**: How much information TPOT communicates while it is running. 0 = none, 1 = minimal, 2 = high, 3 = all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                              \n",
      "Generation 1 - Current best internal CV score: 0.9828564456103959\n",
      "                                                                              \n",
      "Generation 2 - Current best internal CV score: 0.9828564456103959\n",
      "                                                                              \n",
      "Generation 3 - Current best internal CV score: 0.9828564456103959\n",
      "                                                                              \n",
      "Generation 4 - Current best internal CV score: 0.9833089296971915\n",
      "                                                                              \n",
      "Generation 5 - Current best internal CV score: 0.9833089296971915\n",
      "                                                                              \n",
      "Best pipeline: GradientBoostingClassifier(CombineDFs(input_matrix, input_matrix), learning_rate=0.5, max_depth=5, max_features=0.1, min_samples_leaf=15, min_samples_split=2, n_estimators=100, subsample=0.6000000000000001)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Fit data\n",
    "tpot.fit(x_train, y_train)\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boosting Classifier**: a group of machine learning algorithms that combine many weak learning models together to create a strong predictive model. Decision trees are usually used when doing gradient boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, accuracy is used for classification and mean squared error (MSE) is used for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "time: 737.4866428375244\n",
      "Mean Absolute Error: 0.019978969505783387\n",
      "Mean Squared Error: 0.019978969505783387\n",
      "Coef of Determination, R2: 0.9198884494653023\n",
      "Accuracy from tpot 0.9800210304942166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:765: FutureWarning: sklearn.metrics.SCORERS is deprecated and will be removed in v1.3. Please use sklearn.metrics.get_scorer_names to get a list of available scorers and sklearn.metrics.get_metric to get scorer.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "y_pred = tpot.predict(x_test)\n",
    "\n",
    "print('\\ntime:',(end-start))\n",
    "print('Mean Absolute Error:',mean_absolute_error(y_pred=y_pred, y_true=y_test))\n",
    "print('Mean Squared Error:',mean_squared_error(y_pred=y_pred, y_true=y_test))\n",
    "print('Coef of Determination, R2:',r2_score(y_pred=y_pred, y_true=y_test))\n",
    "print('Accuracy from tpot',tpot.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MAE**: measures the average of the residuals in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MSE**: average of the squared difference between the original and predicted values in the data set. Measures the variance of the residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$R^{2}$**: represents the coefficient of how well the values fit compared to the original values. The value from 0 to 1 interpreted as percentages. The higher the value is, the better the model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the result\n",
    "tpot.export('TPOTClassifier_ml_pipeline.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The 'TPOTClassifier_ml_pipeline.py' file will contain the Python code for the optimized pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.ensemble</span> <span class=\"kn\">import</span> <span class=\"n\">GradientBoostingClassifier</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">train_test_split</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.pipeline</span> <span class=\"kn\">import</span> <span class=\"n\">make_pipeline</span><span class=\"p\">,</span> <span class=\"n\">make_union</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">tpot.builtins</span> <span class=\"kn\">import</span> <span class=\"n\">StackingEstimator</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.preprocessing</span> <span class=\"kn\">import</span> <span class=\"n\">FunctionTransformer</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">copy</span> <span class=\"kn\">import</span> <span class=\"kp\">copy</span>\n",
       "\n",
       "<span class=\"c1\"># NOTE: Make sure that the outcome column is labeled &#39;target&#39; in the data file</span>\n",
       "<span class=\"n\">tpot_data</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s1\">&#39;PATH/TO/DATA/FILE&#39;</span><span class=\"p\">,</span> <span class=\"n\">sep</span><span class=\"o\">=</span><span class=\"s1\">&#39;COLUMN_SEPARATOR&#39;</span><span class=\"p\">,</span> <span class=\"kp\">dtype</span><span class=\"o\">=</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float64</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">features</span> <span class=\"o\">=</span> <span class=\"n\">tpot_data</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"s1\">&#39;target&#39;</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">training_features</span><span class=\"p\">,</span> <span class=\"n\">testing_features</span><span class=\"p\">,</span> <span class=\"n\">training_target</span><span class=\"p\">,</span> <span class=\"n\">testing_target</span> <span class=\"o\">=</span> \\\n",
       "            <span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">tpot_data</span><span class=\"p\">[</span><span class=\"s1\">&#39;target&#39;</span><span class=\"p\">],</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Average CV score on the training set was: 0.9833089296971915</span>\n",
       "<span class=\"n\">exported_pipeline</span> <span class=\"o\">=</span> <span class=\"n\">make_pipeline</span><span class=\"p\">(</span>\n",
       "    <span class=\"n\">make_union</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">FunctionTransformer</span><span class=\"p\">(</span><span class=\"kp\">copy</span><span class=\"p\">),</span>\n",
       "        <span class=\"n\">FunctionTransformer</span><span class=\"p\">(</span><span class=\"kp\">copy</span><span class=\"p\">)</span>\n",
       "    <span class=\"p\">),</span>\n",
       "    <span class=\"n\">GradientBoostingClassifier</span><span class=\"p\">(</span><span class=\"n\">learning_rate</span><span class=\"o\">=</span><span class=\"mf\">0.5</span><span class=\"p\">,</span> <span class=\"n\">max_depth</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">max_features</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">,</span> <span class=\"n\">min_samples_leaf</span><span class=\"o\">=</span><span class=\"mi\">15</span><span class=\"p\">,</span> <span class=\"n\">min_samples_split</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">n_estimators</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">subsample</span><span class=\"o\">=</span><span class=\"mf\">0.6000000000000001</span><span class=\"p\">)</span>\n",
       "<span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"n\">exported_pipeline</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">training_features</span><span class=\"p\">,</span> <span class=\"n\">training_target</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"n\">exported_pipeline</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">testing_features</span><span class=\"p\">)</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{numpy} \\PY{k}{as} \\PY{n+nn}{np}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{pandas} \\PY{k}{as} \\PY{n+nn}{pd}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{ensemble} \\PY{k+kn}{import} \\PY{n}{GradientBoostingClassifier}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{model\\PYZus{}selection} \\PY{k+kn}{import} \\PY{n}{train\\PYZus{}test\\PYZus{}split}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{pipeline} \\PY{k+kn}{import} \\PY{n}{make\\PYZus{}pipeline}\\PY{p}{,} \\PY{n}{make\\PYZus{}union}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{tpot}\\PY{n+nn}{.}\\PY{n+nn}{builtins} \\PY{k+kn}{import} \\PY{n}{StackingEstimator}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{preprocessing} \\PY{k+kn}{import} \\PY{n}{FunctionTransformer}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{copy} \\PY{k+kn}{import} \\PY{k+kp}{copy}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} NOTE: Make sure that the outcome column is labeled \\PYZsq{}target\\PYZsq{} in the data file}\n",
       "\\PY{n}{tpot\\PYZus{}data} \\PY{o}{=} \\PY{n}{pd}\\PY{o}{.}\\PY{n}{read\\PYZus{}csv}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{PATH/TO/DATA/FILE}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{sep}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{COLUMN\\PYZus{}SEPARATOR}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{k+kp}{dtype}\\PY{o}{=}\\PY{n}{np}\\PY{o}{.}\\PY{n}{float64}\\PY{p}{)}\n",
       "\\PY{n}{features} \\PY{o}{=} \\PY{n}{tpot\\PYZus{}data}\\PY{o}{.}\\PY{n}{drop}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{target}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{)}\n",
       "\\PY{n}{training\\PYZus{}features}\\PY{p}{,} \\PY{n}{testing\\PYZus{}features}\\PY{p}{,} \\PY{n}{training\\PYZus{}target}\\PY{p}{,} \\PY{n}{testing\\PYZus{}target} \\PY{o}{=} \\PYZbs{}\n",
       "            \\PY{n}{train\\PYZus{}test\\PYZus{}split}\\PY{p}{(}\\PY{n}{features}\\PY{p}{,} \\PY{n}{tpot\\PYZus{}data}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{target}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{random\\PYZus{}state}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Average CV score on the training set was: 0.9833089296971915}\n",
       "\\PY{n}{exported\\PYZus{}pipeline} \\PY{o}{=} \\PY{n}{make\\PYZus{}pipeline}\\PY{p}{(}\n",
       "    \\PY{n}{make\\PYZus{}union}\\PY{p}{(}\n",
       "        \\PY{n}{FunctionTransformer}\\PY{p}{(}\\PY{k+kp}{copy}\\PY{p}{)}\\PY{p}{,}\n",
       "        \\PY{n}{FunctionTransformer}\\PY{p}{(}\\PY{k+kp}{copy}\\PY{p}{)}\n",
       "    \\PY{p}{)}\\PY{p}{,}\n",
       "    \\PY{n}{GradientBoostingClassifier}\\PY{p}{(}\\PY{n}{learning\\PYZus{}rate}\\PY{o}{=}\\PY{l+m+mf}{0.5}\\PY{p}{,} \\PY{n}{max\\PYZus{}depth}\\PY{o}{=}\\PY{l+m+mi}{5}\\PY{p}{,} \\PY{n}{max\\PYZus{}features}\\PY{o}{=}\\PY{l+m+mf}{0.1}\\PY{p}{,} \\PY{n}{min\\PYZus{}samples\\PYZus{}leaf}\\PY{o}{=}\\PY{l+m+mi}{15}\\PY{p}{,} \\PY{n}{min\\PYZus{}samples\\PYZus{}split}\\PY{o}{=}\\PY{l+m+mi}{2}\\PY{p}{,} \\PY{n}{n\\PYZus{}estimators}\\PY{o}{=}\\PY{l+m+mi}{100}\\PY{p}{,} \\PY{n}{subsample}\\PY{o}{=}\\PY{l+m+mf}{0.6000000000000001}\\PY{p}{)}\n",
       "\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{exported\\PYZus{}pipeline}\\PY{o}{.}\\PY{n}{fit}\\PY{p}{(}\\PY{n}{training\\PYZus{}features}\\PY{p}{,} \\PY{n}{training\\PYZus{}target}\\PY{p}{)}\n",
       "\\PY{n}{results} \\PY{o}{=} \\PY{n}{exported\\PYZus{}pipeline}\\PY{o}{.}\\PY{n}{predict}\\PY{p}{(}\\PY{n}{testing\\PYZus{}features}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "import numpy as np\n",
       "import pandas as pd\n",
       "from sklearn.ensemble import GradientBoostingClassifier\n",
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn.pipeline import make_pipeline, make_union\n",
       "from tpot.builtins import StackingEstimator\n",
       "from sklearn.preprocessing import FunctionTransformer\n",
       "from copy import copy\n",
       "\n",
       "# NOTE: Make sure that the outcome column is labeled 'target' in the data file\n",
       "tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\n",
       "features = tpot_data.drop('target', axis=1)\n",
       "training_features, testing_features, training_target, testing_target = \\\n",
       "            train_test_split(features, tpot_data['target'], random_state=None)\n",
       "\n",
       "# Average CV score on the training set was: 0.9833089296971915\n",
       "exported_pipeline = make_pipeline(\n",
       "    make_union(\n",
       "        FunctionTransformer(copy),\n",
       "        FunctionTransformer(copy)\n",
       "    ),\n",
       "    GradientBoostingClassifier(learning_rate=0.5, max_depth=5, max_features=0.1, min_samples_leaf=15, min_samples_split=2, n_estimators=100, subsample=0.6000000000000001)\n",
       ")\n",
       "\n",
       "exported_pipeline.fit(training_features, training_target)\n",
       "results = exported_pipeline.predict(testing_features)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.display.Code('https://raw.githubusercontent.com/20b2122/AutoML-using-TPOT-in-python/main/Voice/TPOTClassifier_ml_pipeline.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "- preparing the predicted(y_pred) data to be shown in a table with x_test and y_test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.160514</td>\n",
       "      <td>0.076767</td>\n",
       "      <td>0.144337</td>\n",
       "      <td>0.110532</td>\n",
       "      <td>0.231962</td>\n",
       "      <td>0.121430</td>\n",
       "      <td>1.397156</td>\n",
       "      <td>4.766611</td>\n",
       "      <td>0.959255</td>\n",
       "      <td>0.719858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093052</td>\n",
       "      <td>0.017758</td>\n",
       "      <td>0.144144</td>\n",
       "      <td>0.301339</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.283937</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.137343</td>\n",
       "      <td>0.080877</td>\n",
       "      <td>0.124263</td>\n",
       "      <td>0.083145</td>\n",
       "      <td>0.209227</td>\n",
       "      <td>0.126082</td>\n",
       "      <td>1.378728</td>\n",
       "      <td>5.008952</td>\n",
       "      <td>0.963514</td>\n",
       "      <td>0.736150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092644</td>\n",
       "      <td>0.016789</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.481671</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>5.015625</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.183115</td>\n",
       "      <td>0.066982</td>\n",
       "      <td>0.191233</td>\n",
       "      <td>0.129149</td>\n",
       "      <td>0.240152</td>\n",
       "      <td>0.111004</td>\n",
       "      <td>3.568104</td>\n",
       "      <td>35.384748</td>\n",
       "      <td>0.940333</td>\n",
       "      <td>0.571394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102799</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>1.245739</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>6.742188</td>\n",
       "      <td>6.539062</td>\n",
       "      <td>0.139332</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.171247</td>\n",
       "      <td>0.074872</td>\n",
       "      <td>0.152807</td>\n",
       "      <td>0.122391</td>\n",
       "      <td>0.243617</td>\n",
       "      <td>0.121227</td>\n",
       "      <td>3.207170</td>\n",
       "      <td>25.765565</td>\n",
       "      <td>0.936954</td>\n",
       "      <td>0.586420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079718</td>\n",
       "      <td>0.015671</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.106279</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.138355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>0.201806</td>\n",
       "      <td>0.036057</td>\n",
       "      <td>0.201622</td>\n",
       "      <td>0.178165</td>\n",
       "      <td>0.227872</td>\n",
       "      <td>0.049707</td>\n",
       "      <td>1.585353</td>\n",
       "      <td>4.945634</td>\n",
       "      <td>0.884731</td>\n",
       "      <td>0.227903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191704</td>\n",
       "      <td>0.032720</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.921875</td>\n",
       "      <td>5.914062</td>\n",
       "      <td>0.124383</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>0.183667</td>\n",
       "      <td>0.040607</td>\n",
       "      <td>0.182534</td>\n",
       "      <td>0.156480</td>\n",
       "      <td>0.207646</td>\n",
       "      <td>0.051166</td>\n",
       "      <td>2.054138</td>\n",
       "      <td>7.483019</td>\n",
       "      <td>0.898138</td>\n",
       "      <td>0.313925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149237</td>\n",
       "      <td>0.018648</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.550312</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>3.421875</td>\n",
       "      <td>3.414062</td>\n",
       "      <td>0.166503</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>0.131884</td>\n",
       "      <td>0.084734</td>\n",
       "      <td>0.153707</td>\n",
       "      <td>0.049285</td>\n",
       "      <td>0.201144</td>\n",
       "      <td>0.151859</td>\n",
       "      <td>1.762129</td>\n",
       "      <td>6.630383</td>\n",
       "      <td>0.962934</td>\n",
       "      <td>0.763182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182790</td>\n",
       "      <td>0.083770</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.832899</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.210938</td>\n",
       "      <td>4.203125</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>0.116221</td>\n",
       "      <td>0.089221</td>\n",
       "      <td>0.076758</td>\n",
       "      <td>0.042718</td>\n",
       "      <td>0.204911</td>\n",
       "      <td>0.162193</td>\n",
       "      <td>0.693730</td>\n",
       "      <td>2.503954</td>\n",
       "      <td>0.960716</td>\n",
       "      <td>0.709570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188980</td>\n",
       "      <td>0.034409</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.909856</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>3.679688</td>\n",
       "      <td>3.640625</td>\n",
       "      <td>0.277897</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.092884</td>\n",
       "      <td>0.183044</td>\n",
       "      <td>0.070072</td>\n",
       "      <td>0.250827</td>\n",
       "      <td>0.180756</td>\n",
       "      <td>1.705029</td>\n",
       "      <td>5.769115</td>\n",
       "      <td>0.938829</td>\n",
       "      <td>0.601529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185607</td>\n",
       "      <td>0.062257</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.227022</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>951 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0    0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1    0.160514  0.076767  0.144337  0.110532  0.231962  0.121430   1.397156   \n",
       "2    0.137343  0.080877  0.124263  0.083145  0.209227  0.126082   1.378728   \n",
       "3    0.183115  0.066982  0.191233  0.129149  0.240152  0.111004   3.568104   \n",
       "4    0.171247  0.074872  0.152807  0.122391  0.243617  0.121227   3.207170   \n",
       "..        ...       ...       ...       ...       ...       ...        ...   \n",
       "946  0.201806  0.036057  0.201622  0.178165  0.227872  0.049707   1.585353   \n",
       "947  0.183667  0.040607  0.182534  0.156480  0.207646  0.051166   2.054138   \n",
       "948  0.131884  0.084734  0.153707  0.049285  0.201144  0.151859   1.762129   \n",
       "949  0.116221  0.089221  0.076758  0.042718  0.204911  0.162193   0.693730   \n",
       "950  0.165509  0.092884  0.183044  0.070072  0.250827  0.180756   1.705029   \n",
       "\n",
       "           kurt    sp.ent       sfm  ...   meanfun    minfun    maxfun  \\\n",
       "0    274.402906  0.893369  0.491918  ...  0.084279  0.015702  0.275862   \n",
       "1      4.766611  0.959255  0.719858  ...  0.093052  0.017758  0.144144   \n",
       "2      5.008952  0.963514  0.736150  ...  0.092644  0.016789  0.213333   \n",
       "3     35.384748  0.940333  0.571394  ...  0.102799  0.020833  0.275862   \n",
       "4     25.765565  0.936954  0.586420  ...  0.079718  0.015671  0.262295   \n",
       "..          ...       ...       ...  ...       ...       ...       ...   \n",
       "946    4.945634  0.884731  0.227903  ...  0.191704  0.032720  0.275862   \n",
       "947    7.483019  0.898138  0.313925  ...  0.149237  0.018648  0.262295   \n",
       "948    6.630383  0.962934  0.763182  ...  0.182790  0.083770  0.262295   \n",
       "949    2.503954  0.960716  0.709570  ...  0.188980  0.034409  0.275862   \n",
       "950    5.769115  0.938829  0.601529  ...  0.185607  0.062257  0.271186   \n",
       "\n",
       "      meandom    mindom    maxdom   dfrange   modindx  label  pred_label  \n",
       "0    0.007812  0.007812  0.007812  0.000000  0.000000      0           0  \n",
       "1    0.301339  0.007812  0.539062  0.531250  0.283937      0           0  \n",
       "2    0.481671  0.015625  5.015625  5.000000  0.088500      0           0  \n",
       "3    1.245739  0.203125  6.742188  6.539062  0.139332      0           0  \n",
       "4    0.106279  0.007812  0.570312  0.562500  0.138355      0           0  \n",
       "..        ...       ...       ...       ...       ...    ...         ...  \n",
       "946  0.593750  0.007812  5.921875  5.914062  0.124383      1           1  \n",
       "947  0.550312  0.007812  3.421875  3.414062  0.166503      1           1  \n",
       "948  0.832899  0.007812  4.210938  4.203125  0.161929      1           1  \n",
       "949  0.909856  0.039062  3.679688  3.640625  0.277897      1           1  \n",
       "950  0.227022  0.007812  0.554688  0.546875  0.350000      1           1  \n",
       "\n",
       "[951 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to ensure one the tables are joined the data are aligned\n",
    "sort_x = x_test.sort_index()\n",
    "new_x = sort_x.reset_index().drop(columns=['index'])\n",
    "\n",
    "sort_y = y_test.sort_index()\n",
    "new_y = sort_y.reset_index().drop(columns=['index'])\n",
    "\n",
    "# converting the array into list then into a table\n",
    "new_y_pred = tpot.predict(new_x).tolist() \n",
    "predictions = pd.DataFrame({ 'pred_label':new_y_pred }) \n",
    "\n",
    "new_table = pd.concat([new_x, new_y, predictions], axis=1)\n",
    "new_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test sample wrongly predicted: 19\n"
     ]
    }
   ],
   "source": [
    "wrong_prediction = np.where(new_table['label'] != new_table['pred_label'])\n",
    "# print(wrong_prediction)\n",
    "print(\"Total number of test sample wrongly predicted:\",len(wrong_prediction[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.167334</td>\n",
       "      <td>0.047178</td>\n",
       "      <td>0.161802</td>\n",
       "      <td>0.135475</td>\n",
       "      <td>0.180725</td>\n",
       "      <td>0.045250</td>\n",
       "      <td>3.961908</td>\n",
       "      <td>24.419622</td>\n",
       "      <td>0.880375</td>\n",
       "      <td>0.344307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.016032</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>6.921875</td>\n",
       "      <td>6.796875</td>\n",
       "      <td>0.021648</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.200830</td>\n",
       "      <td>0.053066</td>\n",
       "      <td>0.210059</td>\n",
       "      <td>0.185332</td>\n",
       "      <td>0.236198</td>\n",
       "      <td>0.050866</td>\n",
       "      <td>1.840901</td>\n",
       "      <td>6.006801</td>\n",
       "      <td>0.907683</td>\n",
       "      <td>0.386818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165155</td>\n",
       "      <td>0.015764</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>1.067057</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>5.593750</td>\n",
       "      <td>5.523438</td>\n",
       "      <td>0.336376</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.224382</td>\n",
       "      <td>0.048547</td>\n",
       "      <td>0.240617</td>\n",
       "      <td>0.220672</td>\n",
       "      <td>0.255481</td>\n",
       "      <td>0.034809</td>\n",
       "      <td>3.095413</td>\n",
       "      <td>15.076874</td>\n",
       "      <td>0.858363</td>\n",
       "      <td>0.130449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138002</td>\n",
       "      <td>0.031873</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.897866</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.734375</td>\n",
       "      <td>5.726562</td>\n",
       "      <td>0.176654</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.138336</td>\n",
       "      <td>0.085693</td>\n",
       "      <td>0.126748</td>\n",
       "      <td>0.060881</td>\n",
       "      <td>0.238669</td>\n",
       "      <td>0.177788</td>\n",
       "      <td>2.668286</td>\n",
       "      <td>13.514607</td>\n",
       "      <td>0.943047</td>\n",
       "      <td>0.611900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138233</td>\n",
       "      <td>0.016360</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>1.106213</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.421875</td>\n",
       "      <td>4.414062</td>\n",
       "      <td>0.230973</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.160468</td>\n",
       "      <td>0.077851</td>\n",
       "      <td>0.149529</td>\n",
       "      <td>0.125194</td>\n",
       "      <td>0.239979</td>\n",
       "      <td>0.114785</td>\n",
       "      <td>2.907550</td>\n",
       "      <td>19.862833</td>\n",
       "      <td>0.940861</td>\n",
       "      <td>0.610161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141772</td>\n",
       "      <td>0.016967</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.350507</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.882812</td>\n",
       "      <td>4.875000</td>\n",
       "      <td>0.119712</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.137655</td>\n",
       "      <td>0.084477</td>\n",
       "      <td>0.133981</td>\n",
       "      <td>0.072697</td>\n",
       "      <td>0.222624</td>\n",
       "      <td>0.149927</td>\n",
       "      <td>3.999052</td>\n",
       "      <td>42.125516</td>\n",
       "      <td>0.933738</td>\n",
       "      <td>0.575355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148467</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.280273</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.453125</td>\n",
       "      <td>4.445312</td>\n",
       "      <td>0.107741</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.129003</td>\n",
       "      <td>0.070466</td>\n",
       "      <td>0.134949</td>\n",
       "      <td>0.070524</td>\n",
       "      <td>0.170783</td>\n",
       "      <td>0.100259</td>\n",
       "      <td>1.298188</td>\n",
       "      <td>4.588312</td>\n",
       "      <td>0.964036</td>\n",
       "      <td>0.727164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139353</td>\n",
       "      <td>0.019208</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.298573</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>3.609375</td>\n",
       "      <td>3.578125</td>\n",
       "      <td>0.103764</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.125830</td>\n",
       "      <td>0.077782</td>\n",
       "      <td>0.128703</td>\n",
       "      <td>0.055812</td>\n",
       "      <td>0.170730</td>\n",
       "      <td>0.114918</td>\n",
       "      <td>1.330019</td>\n",
       "      <td>5.444218</td>\n",
       "      <td>0.967389</td>\n",
       "      <td>0.712792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136684</td>\n",
       "      <td>0.015810</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.242898</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.492188</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>0.052860</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.145676</td>\n",
       "      <td>0.066909</td>\n",
       "      <td>0.145363</td>\n",
       "      <td>0.116707</td>\n",
       "      <td>0.172739</td>\n",
       "      <td>0.056032</td>\n",
       "      <td>1.928249</td>\n",
       "      <td>6.910776</td>\n",
       "      <td>0.935388</td>\n",
       "      <td>0.564341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120921</td>\n",
       "      <td>0.015764</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.360625</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.976562</td>\n",
       "      <td>0.062794</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.092579</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>0.066576</td>\n",
       "      <td>0.016433</td>\n",
       "      <td>0.166652</td>\n",
       "      <td>0.150218</td>\n",
       "      <td>3.570619</td>\n",
       "      <td>19.677106</td>\n",
       "      <td>0.931496</td>\n",
       "      <td>0.617675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160002</td>\n",
       "      <td>0.021080</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>0.698017</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.703125</td>\n",
       "      <td>5.695312</td>\n",
       "      <td>0.139808</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.091436</td>\n",
       "      <td>0.077062</td>\n",
       "      <td>0.070372</td>\n",
       "      <td>0.023457</td>\n",
       "      <td>0.153963</td>\n",
       "      <td>0.130505</td>\n",
       "      <td>2.354569</td>\n",
       "      <td>9.180173</td>\n",
       "      <td>0.956468</td>\n",
       "      <td>0.731009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161466</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>0.776278</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>6.117188</td>\n",
       "      <td>0.121208</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>0.176335</td>\n",
       "      <td>0.060897</td>\n",
       "      <td>0.168465</td>\n",
       "      <td>0.149488</td>\n",
       "      <td>0.224232</td>\n",
       "      <td>0.074744</td>\n",
       "      <td>2.357491</td>\n",
       "      <td>10.318722</td>\n",
       "      <td>0.922532</td>\n",
       "      <td>0.528765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136946</td>\n",
       "      <td>0.047809</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.916932</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>3.656250</td>\n",
       "      <td>3.632812</td>\n",
       "      <td>0.147037</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>0.212146</td>\n",
       "      <td>0.047721</td>\n",
       "      <td>0.218718</td>\n",
       "      <td>0.186476</td>\n",
       "      <td>0.247644</td>\n",
       "      <td>0.061168</td>\n",
       "      <td>1.807250</td>\n",
       "      <td>6.613041</td>\n",
       "      <td>0.912854</td>\n",
       "      <td>0.302727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117417</td>\n",
       "      <td>0.017621</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.765244</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>6.296875</td>\n",
       "      <td>6.289062</td>\n",
       "      <td>0.141246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>0.085606</td>\n",
       "      <td>0.072142</td>\n",
       "      <td>0.058710</td>\n",
       "      <td>0.025865</td>\n",
       "      <td>0.139589</td>\n",
       "      <td>0.113724</td>\n",
       "      <td>2.281377</td>\n",
       "      <td>10.178822</td>\n",
       "      <td>0.943110</td>\n",
       "      <td>0.636657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124927</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.188859</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250496</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>0.222557</td>\n",
       "      <td>0.045202</td>\n",
       "      <td>0.238093</td>\n",
       "      <td>0.191916</td>\n",
       "      <td>0.257045</td>\n",
       "      <td>0.065129</td>\n",
       "      <td>2.212285</td>\n",
       "      <td>9.121702</td>\n",
       "      <td>0.877130</td>\n",
       "      <td>0.189703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130828</td>\n",
       "      <td>0.016512</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.554957</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.429688</td>\n",
       "      <td>5.421875</td>\n",
       "      <td>0.136785</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0.173372</td>\n",
       "      <td>0.073989</td>\n",
       "      <td>0.190638</td>\n",
       "      <td>0.131436</td>\n",
       "      <td>0.228617</td>\n",
       "      <td>0.097181</td>\n",
       "      <td>1.908471</td>\n",
       "      <td>7.353245</td>\n",
       "      <td>0.943016</td>\n",
       "      <td>0.610966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112939</td>\n",
       "      <td>0.016343</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.276242</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>1.070312</td>\n",
       "      <td>1.062500</td>\n",
       "      <td>0.237036</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>0.179889</td>\n",
       "      <td>0.067810</td>\n",
       "      <td>0.163096</td>\n",
       "      <td>0.137244</td>\n",
       "      <td>0.246925</td>\n",
       "      <td>0.109681</td>\n",
       "      <td>2.106748</td>\n",
       "      <td>8.030296</td>\n",
       "      <td>0.932428</td>\n",
       "      <td>0.551025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136662</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.963949</td>\n",
       "      <td>0.043945</td>\n",
       "      <td>3.999023</td>\n",
       "      <td>3.955078</td>\n",
       "      <td>0.261785</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>0.178375</td>\n",
       "      <td>0.060788</td>\n",
       "      <td>0.169630</td>\n",
       "      <td>0.145926</td>\n",
       "      <td>0.225556</td>\n",
       "      <td>0.079630</td>\n",
       "      <td>1.878044</td>\n",
       "      <td>6.475669</td>\n",
       "      <td>0.929118</td>\n",
       "      <td>0.517921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127715</td>\n",
       "      <td>0.009785</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.498259</td>\n",
       "      <td>0.151367</td>\n",
       "      <td>1.425781</td>\n",
       "      <td>1.274414</td>\n",
       "      <td>0.447671</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>0.177548</td>\n",
       "      <td>0.064797</td>\n",
       "      <td>0.168178</td>\n",
       "      <td>0.140357</td>\n",
       "      <td>0.236662</td>\n",
       "      <td>0.096306</td>\n",
       "      <td>1.506238</td>\n",
       "      <td>5.026300</td>\n",
       "      <td>0.942621</td>\n",
       "      <td>0.586907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127532</td>\n",
       "      <td>0.014815</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>1.015625</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>3.964844</td>\n",
       "      <td>3.959961</td>\n",
       "      <td>0.186095</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     meanfreq        sd    median       Q25       Q75       IQR      skew  \\\n",
       "20   0.167334  0.047178  0.161802  0.135475  0.180725  0.045250  3.961908   \n",
       "23   0.200830  0.053066  0.210059  0.185332  0.236198  0.050866  1.840901   \n",
       "90   0.224382  0.048547  0.240617  0.220672  0.255481  0.034809  3.095413   \n",
       "167  0.138336  0.085693  0.126748  0.060881  0.238669  0.177788  2.668286   \n",
       "174  0.160468  0.077851  0.149529  0.125194  0.239979  0.114785  2.907550   \n",
       "175  0.137655  0.084477  0.133981  0.072697  0.222624  0.149927  3.999052   \n",
       "182  0.129003  0.070466  0.134949  0.070524  0.170783  0.100259  1.298188   \n",
       "183  0.125830  0.077782  0.128703  0.055812  0.170730  0.114918  1.330019   \n",
       "184  0.145676  0.066909  0.145363  0.116707  0.172739  0.056032  1.928249   \n",
       "215  0.092579  0.080289  0.066576  0.016433  0.166652  0.150218  3.570619   \n",
       "216  0.091436  0.077062  0.070372  0.023457  0.153963  0.130505  2.354569   \n",
       "323  0.176335  0.060897  0.168465  0.149488  0.224232  0.074744  2.357491   \n",
       "464  0.212146  0.047721  0.218718  0.186476  0.247644  0.061168  1.807250   \n",
       "591  0.085606  0.072142  0.058710  0.025865  0.139589  0.113724  2.281377   \n",
       "605  0.222557  0.045202  0.238093  0.191916  0.257045  0.065129  2.212285   \n",
       "882  0.173372  0.073989  0.190638  0.131436  0.228617  0.097181  1.908471   \n",
       "899  0.179889  0.067810  0.163096  0.137244  0.246925  0.109681  2.106748   \n",
       "900  0.178375  0.060788  0.169630  0.145926  0.225556  0.079630  1.878044   \n",
       "905  0.177548  0.064797  0.168178  0.140357  0.236662  0.096306  1.506238   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...   meanfun    minfun    maxfun  \\\n",
       "20   24.419622  0.880375  0.344307  ...  0.141810  0.016032  0.253968   \n",
       "23    6.006801  0.907683  0.386818  ...  0.165155  0.015764  0.271186   \n",
       "90   15.076874  0.858363  0.130449  ...  0.138002  0.031873  0.275862   \n",
       "167  13.514607  0.943047  0.611900  ...  0.138233  0.016360  0.275862   \n",
       "174  19.862833  0.940861  0.610161  ...  0.141772  0.016967  0.266667   \n",
       "175  42.125516  0.933738  0.575355  ...  0.148467  0.039216  0.271186   \n",
       "182   4.588312  0.964036  0.727164  ...  0.139353  0.019208  0.228571   \n",
       "183   5.444218  0.967389  0.712792  ...  0.136684  0.015810  0.275862   \n",
       "184   6.910776  0.935388  0.564341  ...  0.120921  0.015764  0.205128   \n",
       "215  19.677106  0.931496  0.617675  ...  0.160002  0.021080  0.246154   \n",
       "216   9.180173  0.956468  0.731009  ...  0.161466  0.016529  0.246154   \n",
       "323  10.318722  0.922532  0.528765  ...  0.136946  0.047809  0.275862   \n",
       "464   6.613041  0.912854  0.302727  ...  0.117417  0.017621  0.275862   \n",
       "591  10.178822  0.943110  0.636657  ...  0.124927  0.016129  0.253968   \n",
       "605   9.121702  0.877130  0.189703  ...  0.130828  0.016512  0.275862   \n",
       "882   7.353245  0.943016  0.610966  ...  0.112939  0.016343  0.271186   \n",
       "899   8.030296  0.932428  0.551025  ...  0.136662  0.033898  0.277778   \n",
       "900   6.475669  0.929118  0.517921  ...  0.127715  0.009785  0.196078   \n",
       "905   5.026300  0.942621  0.586907  ...  0.127532  0.014815  0.256410   \n",
       "\n",
       "      meandom    mindom    maxdom   dfrange   modindx  label  pred_label  \n",
       "20   0.578125  0.125000  6.921875  6.796875  0.021648      0           1  \n",
       "23   1.067057  0.070312  5.593750  5.523438  0.336376      0           1  \n",
       "90   0.897866  0.007812  5.734375  5.726562  0.176654      0           1  \n",
       "167  1.106213  0.007812  4.421875  4.414062  0.230973      0           1  \n",
       "174  0.350507  0.007812  4.882812  4.875000  0.119712      0           1  \n",
       "175  0.280273  0.007812  4.453125  4.445312  0.107741      0           1  \n",
       "182  0.298573  0.031250  3.609375  3.578125  0.103764      0           1  \n",
       "183  0.242898  0.007812  5.492188  5.484375  0.052860      0           1  \n",
       "184  0.360625  0.023438  5.000000  4.976562  0.062794      0           1  \n",
       "215  0.698017  0.007812  5.703125  5.695312  0.139808      0           1  \n",
       "216  0.776278  0.007812  6.125000  6.117188  0.121208      0           1  \n",
       "323  0.916932  0.023438  3.656250  3.632812  0.147037      0           1  \n",
       "464  0.765244  0.007812  6.296875  6.289062  0.141246      0           1  \n",
       "591  0.188859  0.007812  0.757812  0.750000  0.250496      1           0  \n",
       "605  0.554957  0.007812  5.429688  5.421875  0.136785      1           0  \n",
       "882  0.276242  0.007812  1.070312  1.062500  0.237036      1           0  \n",
       "899  0.963949  0.043945  3.999023  3.955078  0.261785      1           0  \n",
       "900  0.498259  0.151367  1.425781  1.274414  0.447671      1           0  \n",
       "905  1.015625  0.004883  3.964844  3.959961  0.186095      1           0  \n",
       "\n",
       "[19 rows x 22 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = wrong_prediction\n",
    "\n",
    "new_table.iloc[indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 951 data, only 19 are not prediccted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - ROC Curve: \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - AUC: \n",
      " 0.9803367797541986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# print(f\"Test - Accuracy :  {accuracy_score(y_test, predictions)*100.0:.2f}%\")\n",
    "# print(\"Test - Classification Report: \\n\", metrics.classification_report(y_test, predictions))\n",
    "\n",
    "print(\"Test - ROC Curve: \\n\")\n",
    "fpr, tpr, thresholds = roc_curve(new_y, predictions)\n",
    "plt.plot([0,1], [0,1])\n",
    "plt.plot(fpr, tpr, label='AutoML')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('AutoML ROC curve')\n",
    "plt.show()\n",
    "\n",
    "print('Test - AUC: \\n', roc_auc_score(new_y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - Confusion Matrix: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Confusion Matrix'}, xlabel='Predicted label', ylabel='True label'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "import scikitplot as skplt\n",
    "\n",
    "print(\"Test - Confusion Matrix: \\n\")\n",
    "\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "skplt.metrics.plot_confusion_matrix(new_y, predictions,\n",
    "                                    title=\"Confusion Matrix\",\n",
    "                                    cmap=\"Oranges\",\n",
    "                                    ax=ax1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
