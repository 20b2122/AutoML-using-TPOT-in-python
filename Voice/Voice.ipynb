{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Automated ML Pipeline Generator using TPOT in Python\n",
    "---\n",
    "<br/>\n",
    "\n",
    "### What is TPOT?\n",
    "- Tree-Based Pipeline Optimization Tool (TPOT)\n",
    "- a tool that optimizes machine learning pipelines using genetic programming. \n",
    "- exploring thousands of possible pipelines to find the best one for your data. \n",
    "- Once TPOT is finished searching (or you get tired of waiting), it provides you with the Python code for the best pipeline it found so you can tinker with the pipeline from there. \n",
    "- TPOT makes use of the Python-based scikit-learn library as its ML menu.\n",
    "- pipeline is an independently executable workflow of a complete machine learning task.\n",
    "\n",
    "### To install :\n",
    "    pip install tpot\n",
    "\n",
    "### Dependencies :\n",
    "- scikit learn\n",
    "- numpy \n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data_url = \"https://raw.githubusercontent.com/20b2122/AutoML-using-TPOT-in-python/main/Voice/voice.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "0   274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
       "1   634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
       "2  1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
       "3     4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
       "4     4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
       "\n",
       "     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000   male  \n",
       "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632   male  \n",
       "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512   male  \n",
       "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119   male  \n",
       "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274   male  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "meanfreq    0\n",
       "sd          0\n",
       "median      0\n",
       "Q25         0\n",
       "Q75         0\n",
       "IQR         0\n",
       "skew        0\n",
       "kurt        0\n",
       "sp.ent      0\n",
       "sfm         0\n",
       "mode        0\n",
       "centroid    0\n",
       "meanfun     0\n",
       "minfun      0\n",
       "maxfun      0\n",
       "meandom     0\n",
       "mindom      0\n",
       "maxdom      0\n",
       "dfrange     0\n",
       "modindx     0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 21 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   meanfreq  3168 non-null   float64\n",
      " 1   sd        3168 non-null   float64\n",
      " 2   median    3168 non-null   float64\n",
      " 3   Q25       3168 non-null   float64\n",
      " 4   Q75       3168 non-null   float64\n",
      " 5   IQR       3168 non-null   float64\n",
      " 6   skew      3168 non-null   float64\n",
      " 7   kurt      3168 non-null   float64\n",
      " 8   sp.ent    3168 non-null   float64\n",
      " 9   sfm       3168 non-null   float64\n",
      " 10  mode      3168 non-null   float64\n",
      " 11  centroid  3168 non-null   float64\n",
      " 12  meanfun   3168 non-null   float64\n",
      " 13  minfun    3168 non-null   float64\n",
      " 14  maxfun    3168 non-null   float64\n",
      " 15  meandom   3168 non-null   float64\n",
      " 16  mindom    3168 non-null   float64\n",
      " 17  maxdom    3168 non-null   float64\n",
      " 18  dfrange   3168 non-null   float64\n",
      " 19  modindx   3168 non-null   float64\n",
      " 20  label     3168 non-null   object \n",
      "dtypes: float64(20), object(1)\n",
      "memory usage: 519.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convert Categorical (label) to Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['label'] = df['label'].map({'female': 1, 'male': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "0   274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
       "1   634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
       "2  1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
       "3     4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
       "4     4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
       "\n",
       "     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000      0  \n",
       "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632      0  \n",
       "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512      0  \n",
       "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119      0  \n",
       "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274      0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 21 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   meanfreq  3168 non-null   float64\n",
      " 1   sd        3168 non-null   float64\n",
      " 2   median    3168 non-null   float64\n",
      " 3   Q25       3168 non-null   float64\n",
      " 4   Q75       3168 non-null   float64\n",
      " 5   IQR       3168 non-null   float64\n",
      " 6   skew      3168 non-null   float64\n",
      " 7   kurt      3168 non-null   float64\n",
      " 8   sp.ent    3168 non-null   float64\n",
      " 9   sfm       3168 non-null   float64\n",
      " 10  mode      3168 non-null   float64\n",
      " 11  centroid  3168 non-null   float64\n",
      " 12  meanfun   3168 non-null   float64\n",
      " 13  minfun    3168 non-null   float64\n",
      " 14  maxfun    3168 non-null   float64\n",
      " 15  meandom   3168 non-null   float64\n",
      " 16  mindom    3168 non-null   float64\n",
      " 17  maxdom    3168 non-null   float64\n",
      " 18  dfrange   3168 non-null   float64\n",
      " 19  modindx   3168 non-null   float64\n",
      " 20  label     3168 non-null   int64  \n",
      "dtypes: float64(20), int64(1)\n",
      "memory usage: 519.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info() # double check if all of the categorical has been converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Splitting data into input and output (label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = df.iloc[:,:20] # input\n",
    "y = df.iloc[:,20:] # output - label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\tpot\\builtins\\__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    }
   ],
   "source": [
    "import tpot\n",
    "import time # to calculate how long it takes for the TPOT to finish execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the available methods and attributes at TPOT\n",
    "\n",
    "Using this dataset, we will use TPOTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TPOTClassifier',\n",
       " 'TPOTRegressor',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " '_version',\n",
       " 'base',\n",
       " 'builtins',\n",
       " 'config',\n",
       " 'decorators',\n",
       " 'driver',\n",
       " 'export_utils',\n",
       " 'gp_deap',\n",
       " 'gp_types',\n",
       " 'main',\n",
       " 'metrics',\n",
       " 'operator_utils',\n",
       " 'tpot']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tpot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data in x and y into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "\n",
    "# Init\n",
    "tpot = TPOTClassifier(generations=5, population_size=50, verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generation**: Number of iterations to run the pipeline optimization process.TPOT will work better when you give it more generations (and therefore time) to optimize the pipeline. <br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Population Size**: Number of individuals to retain in the GP population every generation.<br/>\n",
    "<br/>\n",
    "TPOT will evaluate POPULATION_SIZE (50) + GENERATIONS (5) x OFFSPRING_SIZE (50) = 300 pipelines in total.\n",
    "<br/>\n",
    "By default, OFFSPRING_SIZE = POPULATION_SIZE<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verbosity**: How much information TPOT communicates while it is running. 0 = none, 1 = minimal, 2 = high, 3 = all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                              \n",
      "Generation 1 - Current best internal CV score: 0.9828564456103959\n",
      "                                                                              \n",
      "Generation 2 - Current best internal CV score: 0.9828564456103959\n",
      "                                                                              \n",
      "Generation 3 - Current best internal CV score: 0.9828564456103959\n",
      "                                                                              \n",
      "Generation 4 - Current best internal CV score: 0.9833089296971915\n",
      "                                                                              \n",
      "Generation 5 - Current best internal CV score: 0.9833089296971915\n",
      "                                                                              \n",
      "Best pipeline: GradientBoostingClassifier(CombineDFs(input_matrix, input_matrix), learning_rate=0.5, max_depth=5, max_features=0.1, min_samples_leaf=15, min_samples_split=2, n_estimators=100, subsample=0.6000000000000001)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Fit data\n",
    "tpot.fit(x_train, y_train)\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boosting Classifier**: a group of machine learning algorithms that combine many weak learning models together to create a strong predictive model. Decision trees are usually used when doing gradient boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, accuracy is used for classification and mean squared error (MSE) is used for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "time: 737.4866428375244\n",
      "Mean Absolute Error: 0.019978969505783387\n",
      "Mean Squared Error: 0.019978969505783387\n",
      "Coef of Determination, R2: 0.9198884494653023\n",
      "Accuracy from tpot 0.9800210304942166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:765: FutureWarning: sklearn.metrics.SCORERS is deprecated and will be removed in v1.3. Please use sklearn.metrics.get_scorer_names to get a list of available scorers and sklearn.metrics.get_metric to get scorer.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "y_pred = tpot.predict(x_test)\n",
    "\n",
    "print('\\ntime:',(end-start))\n",
    "print('Mean Absolute Error:',mean_absolute_error(y_pred=y_pred, y_true=y_test))\n",
    "print('Mean Squared Error:',mean_squared_error(y_pred=y_pred, y_true=y_test))\n",
    "print('Coef of Determination, R2:',r2_score(y_pred=y_pred, y_true=y_test))\n",
    "print('Accuracy from tpot',tpot.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MAE**: measures the average of the residuals in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MSE**: average of the squared difference between the original and predicted values in the data set. Measures the variance of the residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$R^{2}$**: represents the coefficient of how well the values fit compared to the original values. The value from 0 to 1 interpreted as percentages. The higher the value is, the better the model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the result\n",
    "tpot.export('TPOTClassifier_ml_pipeline.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The 'TPOTClassifier_ml_pipeline.py' file will contain the Python code for the optimized pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.ensemble</span> <span class=\"kn\">import</span> <span class=\"n\">GradientBoostingClassifier</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">train_test_split</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.pipeline</span> <span class=\"kn\">import</span> <span class=\"n\">make_pipeline</span><span class=\"p\">,</span> <span class=\"n\">make_union</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">tpot.builtins</span> <span class=\"kn\">import</span> <span class=\"n\">StackingEstimator</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.preprocessing</span> <span class=\"kn\">import</span> <span class=\"n\">FunctionTransformer</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">copy</span> <span class=\"kn\">import</span> <span class=\"kp\">copy</span>\n",
       "\n",
       "<span class=\"c1\"># NOTE: Make sure that the outcome column is labeled &#39;target&#39; in the data file</span>\n",
       "<span class=\"n\">tpot_data</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s1\">&#39;PATH/TO/DATA/FILE&#39;</span><span class=\"p\">,</span> <span class=\"n\">sep</span><span class=\"o\">=</span><span class=\"s1\">&#39;COLUMN_SEPARATOR&#39;</span><span class=\"p\">,</span> <span class=\"kp\">dtype</span><span class=\"o\">=</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float64</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">features</span> <span class=\"o\">=</span> <span class=\"n\">tpot_data</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"s1\">&#39;target&#39;</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">training_features</span><span class=\"p\">,</span> <span class=\"n\">testing_features</span><span class=\"p\">,</span> <span class=\"n\">training_target</span><span class=\"p\">,</span> <span class=\"n\">testing_target</span> <span class=\"o\">=</span> \\\n",
       "            <span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">tpot_data</span><span class=\"p\">[</span><span class=\"s1\">&#39;target&#39;</span><span class=\"p\">],</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Average CV score on the training set was: 0.9833089296971915</span>\n",
       "<span class=\"n\">exported_pipeline</span> <span class=\"o\">=</span> <span class=\"n\">make_pipeline</span><span class=\"p\">(</span>\n",
       "    <span class=\"n\">make_union</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">FunctionTransformer</span><span class=\"p\">(</span><span class=\"kp\">copy</span><span class=\"p\">),</span>\n",
       "        <span class=\"n\">FunctionTransformer</span><span class=\"p\">(</span><span class=\"kp\">copy</span><span class=\"p\">)</span>\n",
       "    <span class=\"p\">),</span>\n",
       "    <span class=\"n\">GradientBoostingClassifier</span><span class=\"p\">(</span><span class=\"n\">learning_rate</span><span class=\"o\">=</span><span class=\"mf\">0.5</span><span class=\"p\">,</span> <span class=\"n\">max_depth</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">max_features</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">,</span> <span class=\"n\">min_samples_leaf</span><span class=\"o\">=</span><span class=\"mi\">15</span><span class=\"p\">,</span> <span class=\"n\">min_samples_split</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">n_estimators</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">subsample</span><span class=\"o\">=</span><span class=\"mf\">0.6000000000000001</span><span class=\"p\">)</span>\n",
       "<span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"n\">exported_pipeline</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">training_features</span><span class=\"p\">,</span> <span class=\"n\">training_target</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"n\">exported_pipeline</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">testing_features</span><span class=\"p\">)</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{numpy} \\PY{k}{as} \\PY{n+nn}{np}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{pandas} \\PY{k}{as} \\PY{n+nn}{pd}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{ensemble} \\PY{k+kn}{import} \\PY{n}{GradientBoostingClassifier}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{model\\PYZus{}selection} \\PY{k+kn}{import} \\PY{n}{train\\PYZus{}test\\PYZus{}split}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{pipeline} \\PY{k+kn}{import} \\PY{n}{make\\PYZus{}pipeline}\\PY{p}{,} \\PY{n}{make\\PYZus{}union}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{tpot}\\PY{n+nn}{.}\\PY{n+nn}{builtins} \\PY{k+kn}{import} \\PY{n}{StackingEstimator}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{preprocessing} \\PY{k+kn}{import} \\PY{n}{FunctionTransformer}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{copy} \\PY{k+kn}{import} \\PY{k+kp}{copy}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} NOTE: Make sure that the outcome column is labeled \\PYZsq{}target\\PYZsq{} in the data file}\n",
       "\\PY{n}{tpot\\PYZus{}data} \\PY{o}{=} \\PY{n}{pd}\\PY{o}{.}\\PY{n}{read\\PYZus{}csv}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{PATH/TO/DATA/FILE}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{sep}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{COLUMN\\PYZus{}SEPARATOR}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{k+kp}{dtype}\\PY{o}{=}\\PY{n}{np}\\PY{o}{.}\\PY{n}{float64}\\PY{p}{)}\n",
       "\\PY{n}{features} \\PY{o}{=} \\PY{n}{tpot\\PYZus{}data}\\PY{o}{.}\\PY{n}{drop}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{target}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{)}\n",
       "\\PY{n}{training\\PYZus{}features}\\PY{p}{,} \\PY{n}{testing\\PYZus{}features}\\PY{p}{,} \\PY{n}{training\\PYZus{}target}\\PY{p}{,} \\PY{n}{testing\\PYZus{}target} \\PY{o}{=} \\PYZbs{}\n",
       "            \\PY{n}{train\\PYZus{}test\\PYZus{}split}\\PY{p}{(}\\PY{n}{features}\\PY{p}{,} \\PY{n}{tpot\\PYZus{}data}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{target}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{random\\PYZus{}state}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Average CV score on the training set was: 0.9833089296971915}\n",
       "\\PY{n}{exported\\PYZus{}pipeline} \\PY{o}{=} \\PY{n}{make\\PYZus{}pipeline}\\PY{p}{(}\n",
       "    \\PY{n}{make\\PYZus{}union}\\PY{p}{(}\n",
       "        \\PY{n}{FunctionTransformer}\\PY{p}{(}\\PY{k+kp}{copy}\\PY{p}{)}\\PY{p}{,}\n",
       "        \\PY{n}{FunctionTransformer}\\PY{p}{(}\\PY{k+kp}{copy}\\PY{p}{)}\n",
       "    \\PY{p}{)}\\PY{p}{,}\n",
       "    \\PY{n}{GradientBoostingClassifier}\\PY{p}{(}\\PY{n}{learning\\PYZus{}rate}\\PY{o}{=}\\PY{l+m+mf}{0.5}\\PY{p}{,} \\PY{n}{max\\PYZus{}depth}\\PY{o}{=}\\PY{l+m+mi}{5}\\PY{p}{,} \\PY{n}{max\\PYZus{}features}\\PY{o}{=}\\PY{l+m+mf}{0.1}\\PY{p}{,} \\PY{n}{min\\PYZus{}samples\\PYZus{}leaf}\\PY{o}{=}\\PY{l+m+mi}{15}\\PY{p}{,} \\PY{n}{min\\PYZus{}samples\\PYZus{}split}\\PY{o}{=}\\PY{l+m+mi}{2}\\PY{p}{,} \\PY{n}{n\\PYZus{}estimators}\\PY{o}{=}\\PY{l+m+mi}{100}\\PY{p}{,} \\PY{n}{subsample}\\PY{o}{=}\\PY{l+m+mf}{0.6000000000000001}\\PY{p}{)}\n",
       "\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{exported\\PYZus{}pipeline}\\PY{o}{.}\\PY{n}{fit}\\PY{p}{(}\\PY{n}{training\\PYZus{}features}\\PY{p}{,} \\PY{n}{training\\PYZus{}target}\\PY{p}{)}\n",
       "\\PY{n}{results} \\PY{o}{=} \\PY{n}{exported\\PYZus{}pipeline}\\PY{o}{.}\\PY{n}{predict}\\PY{p}{(}\\PY{n}{testing\\PYZus{}features}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "import numpy as np\n",
       "import pandas as pd\n",
       "from sklearn.ensemble import GradientBoostingClassifier\n",
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn.pipeline import make_pipeline, make_union\n",
       "from tpot.builtins import StackingEstimator\n",
       "from sklearn.preprocessing import FunctionTransformer\n",
       "from copy import copy\n",
       "\n",
       "# NOTE: Make sure that the outcome column is labeled 'target' in the data file\n",
       "tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\n",
       "features = tpot_data.drop('target', axis=1)\n",
       "training_features, testing_features, training_target, testing_target = \\\n",
       "            train_test_split(features, tpot_data['target'], random_state=None)\n",
       "\n",
       "# Average CV score on the training set was: 0.9833089296971915\n",
       "exported_pipeline = make_pipeline(\n",
       "    make_union(\n",
       "        FunctionTransformer(copy),\n",
       "        FunctionTransformer(copy)\n",
       "    ),\n",
       "    GradientBoostingClassifier(learning_rate=0.5, max_depth=5, max_features=0.1, min_samples_leaf=15, min_samples_split=2, n_estimators=100, subsample=0.6000000000000001)\n",
       ")\n",
       "\n",
       "exported_pipeline.fit(training_features, training_target)\n",
       "results = exported_pipeline.predict(testing_features)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.display.Code('https://raw.githubusercontent.com/20b2122/AutoML-using-TPOT-in-python/main/Voice/TPOTClassifier_ml_pipeline.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "- preparing the predicted(y_pred) data to be shown in a table with x_test and y_test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.160514</td>\n",
       "      <td>0.076767</td>\n",
       "      <td>0.144337</td>\n",
       "      <td>0.110532</td>\n",
       "      <td>0.231962</td>\n",
       "      <td>0.121430</td>\n",
       "      <td>1.397156</td>\n",
       "      <td>4.766611</td>\n",
       "      <td>0.959255</td>\n",
       "      <td>0.719858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093052</td>\n",
       "      <td>0.017758</td>\n",
       "      <td>0.144144</td>\n",
       "      <td>0.301339</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.283937</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.137343</td>\n",
       "      <td>0.080877</td>\n",
       "      <td>0.124263</td>\n",
       "      <td>0.083145</td>\n",
       "      <td>0.209227</td>\n",
       "      <td>0.126082</td>\n",
       "      <td>1.378728</td>\n",
       "      <td>5.008952</td>\n",
       "      <td>0.963514</td>\n",
       "      <td>0.736150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092644</td>\n",
       "      <td>0.016789</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.481671</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>5.015625</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.183115</td>\n",
       "      <td>0.066982</td>\n",
       "      <td>0.191233</td>\n",
       "      <td>0.129149</td>\n",
       "      <td>0.240152</td>\n",
       "      <td>0.111004</td>\n",
       "      <td>3.568104</td>\n",
       "      <td>35.384748</td>\n",
       "      <td>0.940333</td>\n",
       "      <td>0.571394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102799</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>1.245739</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>6.742188</td>\n",
       "      <td>6.539062</td>\n",
       "      <td>0.139332</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.171247</td>\n",
       "      <td>0.074872</td>\n",
       "      <td>0.152807</td>\n",
       "      <td>0.122391</td>\n",
       "      <td>0.243617</td>\n",
       "      <td>0.121227</td>\n",
       "      <td>3.207170</td>\n",
       "      <td>25.765565</td>\n",
       "      <td>0.936954</td>\n",
       "      <td>0.586420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079718</td>\n",
       "      <td>0.015671</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.106279</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.138355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>0.201806</td>\n",
       "      <td>0.036057</td>\n",
       "      <td>0.201622</td>\n",
       "      <td>0.178165</td>\n",
       "      <td>0.227872</td>\n",
       "      <td>0.049707</td>\n",
       "      <td>1.585353</td>\n",
       "      <td>4.945634</td>\n",
       "      <td>0.884731</td>\n",
       "      <td>0.227903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191704</td>\n",
       "      <td>0.032720</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.921875</td>\n",
       "      <td>5.914062</td>\n",
       "      <td>0.124383</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>0.183667</td>\n",
       "      <td>0.040607</td>\n",
       "      <td>0.182534</td>\n",
       "      <td>0.156480</td>\n",
       "      <td>0.207646</td>\n",
       "      <td>0.051166</td>\n",
       "      <td>2.054138</td>\n",
       "      <td>7.483019</td>\n",
       "      <td>0.898138</td>\n",
       "      <td>0.313925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149237</td>\n",
       "      <td>0.018648</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.550312</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>3.421875</td>\n",
       "      <td>3.414062</td>\n",
       "      <td>0.166503</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>0.131884</td>\n",
       "      <td>0.084734</td>\n",
       "      <td>0.153707</td>\n",
       "      <td>0.049285</td>\n",
       "      <td>0.201144</td>\n",
       "      <td>0.151859</td>\n",
       "      <td>1.762129</td>\n",
       "      <td>6.630383</td>\n",
       "      <td>0.962934</td>\n",
       "      <td>0.763182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182790</td>\n",
       "      <td>0.083770</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.832899</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.210938</td>\n",
       "      <td>4.203125</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>0.116221</td>\n",
       "      <td>0.089221</td>\n",
       "      <td>0.076758</td>\n",
       "      <td>0.042718</td>\n",
       "      <td>0.204911</td>\n",
       "      <td>0.162193</td>\n",
       "      <td>0.693730</td>\n",
       "      <td>2.503954</td>\n",
       "      <td>0.960716</td>\n",
       "      <td>0.709570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188980</td>\n",
       "      <td>0.034409</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.909856</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>3.679688</td>\n",
       "      <td>3.640625</td>\n",
       "      <td>0.277897</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.092884</td>\n",
       "      <td>0.183044</td>\n",
       "      <td>0.070072</td>\n",
       "      <td>0.250827</td>\n",
       "      <td>0.180756</td>\n",
       "      <td>1.705029</td>\n",
       "      <td>5.769115</td>\n",
       "      <td>0.938829</td>\n",
       "      <td>0.601529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185607</td>\n",
       "      <td>0.062257</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.227022</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>951 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0    0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1    0.160514  0.076767  0.144337  0.110532  0.231962  0.121430   1.397156   \n",
       "2    0.137343  0.080877  0.124263  0.083145  0.209227  0.126082   1.378728   \n",
       "3    0.183115  0.066982  0.191233  0.129149  0.240152  0.111004   3.568104   \n",
       "4    0.171247  0.074872  0.152807  0.122391  0.243617  0.121227   3.207170   \n",
       "..        ...       ...       ...       ...       ...       ...        ...   \n",
       "946  0.201806  0.036057  0.201622  0.178165  0.227872  0.049707   1.585353   \n",
       "947  0.183667  0.040607  0.182534  0.156480  0.207646  0.051166   2.054138   \n",
       "948  0.131884  0.084734  0.153707  0.049285  0.201144  0.151859   1.762129   \n",
       "949  0.116221  0.089221  0.076758  0.042718  0.204911  0.162193   0.693730   \n",
       "950  0.165509  0.092884  0.183044  0.070072  0.250827  0.180756   1.705029   \n",
       "\n",
       "           kurt    sp.ent       sfm  ...   meanfun    minfun    maxfun  \\\n",
       "0    274.402906  0.893369  0.491918  ...  0.084279  0.015702  0.275862   \n",
       "1      4.766611  0.959255  0.719858  ...  0.093052  0.017758  0.144144   \n",
       "2      5.008952  0.963514  0.736150  ...  0.092644  0.016789  0.213333   \n",
       "3     35.384748  0.940333  0.571394  ...  0.102799  0.020833  0.275862   \n",
       "4     25.765565  0.936954  0.586420  ...  0.079718  0.015671  0.262295   \n",
       "..          ...       ...       ...  ...       ...       ...       ...   \n",
       "946    4.945634  0.884731  0.227903  ...  0.191704  0.032720  0.275862   \n",
       "947    7.483019  0.898138  0.313925  ...  0.149237  0.018648  0.262295   \n",
       "948    6.630383  0.962934  0.763182  ...  0.182790  0.083770  0.262295   \n",
       "949    2.503954  0.960716  0.709570  ...  0.188980  0.034409  0.275862   \n",
       "950    5.769115  0.938829  0.601529  ...  0.185607  0.062257  0.271186   \n",
       "\n",
       "      meandom    mindom    maxdom   dfrange   modindx  label  pred_label  \n",
       "0    0.007812  0.007812  0.007812  0.000000  0.000000      0           0  \n",
       "1    0.301339  0.007812  0.539062  0.531250  0.283937      0           0  \n",
       "2    0.481671  0.015625  5.015625  5.000000  0.088500      0           0  \n",
       "3    1.245739  0.203125  6.742188  6.539062  0.139332      0           0  \n",
       "4    0.106279  0.007812  0.570312  0.562500  0.138355      0           0  \n",
       "..        ...       ...       ...       ...       ...    ...         ...  \n",
       "946  0.593750  0.007812  5.921875  5.914062  0.124383      1           1  \n",
       "947  0.550312  0.007812  3.421875  3.414062  0.166503      1           1  \n",
       "948  0.832899  0.007812  4.210938  4.203125  0.161929      1           1  \n",
       "949  0.909856  0.039062  3.679688  3.640625  0.277897      1           1  \n",
       "950  0.227022  0.007812  0.554688  0.546875  0.350000      1           1  \n",
       "\n",
       "[951 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to ensure one the tables are joined the data are aligned\n",
    "sort_x = x_test.sort_index()\n",
    "new_x = sort_x.reset_index().drop(columns=['index'])\n",
    "\n",
    "sort_y = y_test.sort_index()\n",
    "new_y = sort_y.reset_index().drop(columns=['index'])\n",
    "\n",
    "# converting the array into list then into a table\n",
    "new_y_pred = tpot.predict(new_x).tolist() \n",
    "predictions = pd.DataFrame({ 'pred_label':new_y_pred }) \n",
    "\n",
    "new_table = pd.concat([new_x, new_y, predictions], axis=1)\n",
    "new_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test sample wrongly predicted: 19\n"
     ]
    }
   ],
   "source": [
    "wrong_prediction = np.where(new_table['label'] != new_table['pred_label'])\n",
    "# print(wrong_prediction)\n",
    "print(\"Total number of test sample wrongly predicted:\",len(wrong_prediction[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.167334</td>\n",
       "      <td>0.047178</td>\n",
       "      <td>0.161802</td>\n",
       "      <td>0.135475</td>\n",
       "      <td>0.180725</td>\n",
       "      <td>0.045250</td>\n",
       "      <td>3.961908</td>\n",
       "      <td>24.419622</td>\n",
       "      <td>0.880375</td>\n",
       "      <td>0.344307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.016032</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>6.921875</td>\n",
       "      <td>6.796875</td>\n",
       "      <td>0.021648</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.200830</td>\n",
       "      <td>0.053066</td>\n",
       "      <td>0.210059</td>\n",
       "      <td>0.185332</td>\n",
       "      <td>0.236198</td>\n",
       "      <td>0.050866</td>\n",
       "      <td>1.840901</td>\n",
       "      <td>6.006801</td>\n",
       "      <td>0.907683</td>\n",
       "      <td>0.386818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165155</td>\n",
       "      <td>0.015764</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>1.067057</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>5.593750</td>\n",
       "      <td>5.523438</td>\n",
       "      <td>0.336376</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.224382</td>\n",
       "      <td>0.048547</td>\n",
       "      <td>0.240617</td>\n",
       "      <td>0.220672</td>\n",
       "      <td>0.255481</td>\n",
       "      <td>0.034809</td>\n",
       "      <td>3.095413</td>\n",
       "      <td>15.076874</td>\n",
       "      <td>0.858363</td>\n",
       "      <td>0.130449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138002</td>\n",
       "      <td>0.031873</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.897866</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.734375</td>\n",
       "      <td>5.726562</td>\n",
       "      <td>0.176654</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.138336</td>\n",
       "      <td>0.085693</td>\n",
       "      <td>0.126748</td>\n",
       "      <td>0.060881</td>\n",
       "      <td>0.238669</td>\n",
       "      <td>0.177788</td>\n",
       "      <td>2.668286</td>\n",
       "      <td>13.514607</td>\n",
       "      <td>0.943047</td>\n",
       "      <td>0.611900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138233</td>\n",
       "      <td>0.016360</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>1.106213</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.421875</td>\n",
       "      <td>4.414062</td>\n",
       "      <td>0.230973</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.160468</td>\n",
       "      <td>0.077851</td>\n",
       "      <td>0.149529</td>\n",
       "      <td>0.125194</td>\n",
       "      <td>0.239979</td>\n",
       "      <td>0.114785</td>\n",
       "      <td>2.907550</td>\n",
       "      <td>19.862833</td>\n",
       "      <td>0.940861</td>\n",
       "      <td>0.610161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141772</td>\n",
       "      <td>0.016967</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.350507</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.882812</td>\n",
       "      <td>4.875000</td>\n",
       "      <td>0.119712</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.137655</td>\n",
       "      <td>0.084477</td>\n",
       "      <td>0.133981</td>\n",
       "      <td>0.072697</td>\n",
       "      <td>0.222624</td>\n",
       "      <td>0.149927</td>\n",
       "      <td>3.999052</td>\n",
       "      <td>42.125516</td>\n",
       "      <td>0.933738</td>\n",
       "      <td>0.575355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148467</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.280273</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.453125</td>\n",
       "      <td>4.445312</td>\n",
       "      <td>0.107741</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.129003</td>\n",
       "      <td>0.070466</td>\n",
       "      <td>0.134949</td>\n",
       "      <td>0.070524</td>\n",
       "      <td>0.170783</td>\n",
       "      <td>0.100259</td>\n",
       "      <td>1.298188</td>\n",
       "      <td>4.588312</td>\n",
       "      <td>0.964036</td>\n",
       "      <td>0.727164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139353</td>\n",
       "      <td>0.019208</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.298573</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>3.609375</td>\n",
       "      <td>3.578125</td>\n",
       "      <td>0.103764</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.125830</td>\n",
       "      <td>0.077782</td>\n",
       "      <td>0.128703</td>\n",
       "      <td>0.055812</td>\n",
       "      <td>0.170730</td>\n",
       "      <td>0.114918</td>\n",
       "      <td>1.330019</td>\n",
       "      <td>5.444218</td>\n",
       "      <td>0.967389</td>\n",
       "      <td>0.712792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136684</td>\n",
       "      <td>0.015810</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.242898</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.492188</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>0.052860</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.145676</td>\n",
       "      <td>0.066909</td>\n",
       "      <td>0.145363</td>\n",
       "      <td>0.116707</td>\n",
       "      <td>0.172739</td>\n",
       "      <td>0.056032</td>\n",
       "      <td>1.928249</td>\n",
       "      <td>6.910776</td>\n",
       "      <td>0.935388</td>\n",
       "      <td>0.564341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120921</td>\n",
       "      <td>0.015764</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.360625</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.976562</td>\n",
       "      <td>0.062794</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.092579</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>0.066576</td>\n",
       "      <td>0.016433</td>\n",
       "      <td>0.166652</td>\n",
       "      <td>0.150218</td>\n",
       "      <td>3.570619</td>\n",
       "      <td>19.677106</td>\n",
       "      <td>0.931496</td>\n",
       "      <td>0.617675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160002</td>\n",
       "      <td>0.021080</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>0.698017</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.703125</td>\n",
       "      <td>5.695312</td>\n",
       "      <td>0.139808</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.091436</td>\n",
       "      <td>0.077062</td>\n",
       "      <td>0.070372</td>\n",
       "      <td>0.023457</td>\n",
       "      <td>0.153963</td>\n",
       "      <td>0.130505</td>\n",
       "      <td>2.354569</td>\n",
       "      <td>9.180173</td>\n",
       "      <td>0.956468</td>\n",
       "      <td>0.731009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161466</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>0.776278</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>6.117188</td>\n",
       "      <td>0.121208</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>0.176335</td>\n",
       "      <td>0.060897</td>\n",
       "      <td>0.168465</td>\n",
       "      <td>0.149488</td>\n",
       "      <td>0.224232</td>\n",
       "      <td>0.074744</td>\n",
       "      <td>2.357491</td>\n",
       "      <td>10.318722</td>\n",
       "      <td>0.922532</td>\n",
       "      <td>0.528765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136946</td>\n",
       "      <td>0.047809</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.916932</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>3.656250</td>\n",
       "      <td>3.632812</td>\n",
       "      <td>0.147037</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>0.212146</td>\n",
       "      <td>0.047721</td>\n",
       "      <td>0.218718</td>\n",
       "      <td>0.186476</td>\n",
       "      <td>0.247644</td>\n",
       "      <td>0.061168</td>\n",
       "      <td>1.807250</td>\n",
       "      <td>6.613041</td>\n",
       "      <td>0.912854</td>\n",
       "      <td>0.302727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117417</td>\n",
       "      <td>0.017621</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.765244</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>6.296875</td>\n",
       "      <td>6.289062</td>\n",
       "      <td>0.141246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>0.085606</td>\n",
       "      <td>0.072142</td>\n",
       "      <td>0.058710</td>\n",
       "      <td>0.025865</td>\n",
       "      <td>0.139589</td>\n",
       "      <td>0.113724</td>\n",
       "      <td>2.281377</td>\n",
       "      <td>10.178822</td>\n",
       "      <td>0.943110</td>\n",
       "      <td>0.636657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124927</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.188859</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250496</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>0.222557</td>\n",
       "      <td>0.045202</td>\n",
       "      <td>0.238093</td>\n",
       "      <td>0.191916</td>\n",
       "      <td>0.257045</td>\n",
       "      <td>0.065129</td>\n",
       "      <td>2.212285</td>\n",
       "      <td>9.121702</td>\n",
       "      <td>0.877130</td>\n",
       "      <td>0.189703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130828</td>\n",
       "      <td>0.016512</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.554957</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.429688</td>\n",
       "      <td>5.421875</td>\n",
       "      <td>0.136785</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0.173372</td>\n",
       "      <td>0.073989</td>\n",
       "      <td>0.190638</td>\n",
       "      <td>0.131436</td>\n",
       "      <td>0.228617</td>\n",
       "      <td>0.097181</td>\n",
       "      <td>1.908471</td>\n",
       "      <td>7.353245</td>\n",
       "      <td>0.943016</td>\n",
       "      <td>0.610966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112939</td>\n",
       "      <td>0.016343</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.276242</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>1.070312</td>\n",
       "      <td>1.062500</td>\n",
       "      <td>0.237036</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>0.179889</td>\n",
       "      <td>0.067810</td>\n",
       "      <td>0.163096</td>\n",
       "      <td>0.137244</td>\n",
       "      <td>0.246925</td>\n",
       "      <td>0.109681</td>\n",
       "      <td>2.106748</td>\n",
       "      <td>8.030296</td>\n",
       "      <td>0.932428</td>\n",
       "      <td>0.551025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136662</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.963949</td>\n",
       "      <td>0.043945</td>\n",
       "      <td>3.999023</td>\n",
       "      <td>3.955078</td>\n",
       "      <td>0.261785</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>0.178375</td>\n",
       "      <td>0.060788</td>\n",
       "      <td>0.169630</td>\n",
       "      <td>0.145926</td>\n",
       "      <td>0.225556</td>\n",
       "      <td>0.079630</td>\n",
       "      <td>1.878044</td>\n",
       "      <td>6.475669</td>\n",
       "      <td>0.929118</td>\n",
       "      <td>0.517921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127715</td>\n",
       "      <td>0.009785</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.498259</td>\n",
       "      <td>0.151367</td>\n",
       "      <td>1.425781</td>\n",
       "      <td>1.274414</td>\n",
       "      <td>0.447671</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>0.177548</td>\n",
       "      <td>0.064797</td>\n",
       "      <td>0.168178</td>\n",
       "      <td>0.140357</td>\n",
       "      <td>0.236662</td>\n",
       "      <td>0.096306</td>\n",
       "      <td>1.506238</td>\n",
       "      <td>5.026300</td>\n",
       "      <td>0.942621</td>\n",
       "      <td>0.586907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127532</td>\n",
       "      <td>0.014815</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>1.015625</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>3.964844</td>\n",
       "      <td>3.959961</td>\n",
       "      <td>0.186095</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     meanfreq        sd    median       Q25       Q75       IQR      skew  \\\n",
       "20   0.167334  0.047178  0.161802  0.135475  0.180725  0.045250  3.961908   \n",
       "23   0.200830  0.053066  0.210059  0.185332  0.236198  0.050866  1.840901   \n",
       "90   0.224382  0.048547  0.240617  0.220672  0.255481  0.034809  3.095413   \n",
       "167  0.138336  0.085693  0.126748  0.060881  0.238669  0.177788  2.668286   \n",
       "174  0.160468  0.077851  0.149529  0.125194  0.239979  0.114785  2.907550   \n",
       "175  0.137655  0.084477  0.133981  0.072697  0.222624  0.149927  3.999052   \n",
       "182  0.129003  0.070466  0.134949  0.070524  0.170783  0.100259  1.298188   \n",
       "183  0.125830  0.077782  0.128703  0.055812  0.170730  0.114918  1.330019   \n",
       "184  0.145676  0.066909  0.145363  0.116707  0.172739  0.056032  1.928249   \n",
       "215  0.092579  0.080289  0.066576  0.016433  0.166652  0.150218  3.570619   \n",
       "216  0.091436  0.077062  0.070372  0.023457  0.153963  0.130505  2.354569   \n",
       "323  0.176335  0.060897  0.168465  0.149488  0.224232  0.074744  2.357491   \n",
       "464  0.212146  0.047721  0.218718  0.186476  0.247644  0.061168  1.807250   \n",
       "591  0.085606  0.072142  0.058710  0.025865  0.139589  0.113724  2.281377   \n",
       "605  0.222557  0.045202  0.238093  0.191916  0.257045  0.065129  2.212285   \n",
       "882  0.173372  0.073989  0.190638  0.131436  0.228617  0.097181  1.908471   \n",
       "899  0.179889  0.067810  0.163096  0.137244  0.246925  0.109681  2.106748   \n",
       "900  0.178375  0.060788  0.169630  0.145926  0.225556  0.079630  1.878044   \n",
       "905  0.177548  0.064797  0.168178  0.140357  0.236662  0.096306  1.506238   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...   meanfun    minfun    maxfun  \\\n",
       "20   24.419622  0.880375  0.344307  ...  0.141810  0.016032  0.253968   \n",
       "23    6.006801  0.907683  0.386818  ...  0.165155  0.015764  0.271186   \n",
       "90   15.076874  0.858363  0.130449  ...  0.138002  0.031873  0.275862   \n",
       "167  13.514607  0.943047  0.611900  ...  0.138233  0.016360  0.275862   \n",
       "174  19.862833  0.940861  0.610161  ...  0.141772  0.016967  0.266667   \n",
       "175  42.125516  0.933738  0.575355  ...  0.148467  0.039216  0.271186   \n",
       "182   4.588312  0.964036  0.727164  ...  0.139353  0.019208  0.228571   \n",
       "183   5.444218  0.967389  0.712792  ...  0.136684  0.015810  0.275862   \n",
       "184   6.910776  0.935388  0.564341  ...  0.120921  0.015764  0.205128   \n",
       "215  19.677106  0.931496  0.617675  ...  0.160002  0.021080  0.246154   \n",
       "216   9.180173  0.956468  0.731009  ...  0.161466  0.016529  0.246154   \n",
       "323  10.318722  0.922532  0.528765  ...  0.136946  0.047809  0.275862   \n",
       "464   6.613041  0.912854  0.302727  ...  0.117417  0.017621  0.275862   \n",
       "591  10.178822  0.943110  0.636657  ...  0.124927  0.016129  0.253968   \n",
       "605   9.121702  0.877130  0.189703  ...  0.130828  0.016512  0.275862   \n",
       "882   7.353245  0.943016  0.610966  ...  0.112939  0.016343  0.271186   \n",
       "899   8.030296  0.932428  0.551025  ...  0.136662  0.033898  0.277778   \n",
       "900   6.475669  0.929118  0.517921  ...  0.127715  0.009785  0.196078   \n",
       "905   5.026300  0.942621  0.586907  ...  0.127532  0.014815  0.256410   \n",
       "\n",
       "      meandom    mindom    maxdom   dfrange   modindx  label  pred_label  \n",
       "20   0.578125  0.125000  6.921875  6.796875  0.021648      0           1  \n",
       "23   1.067057  0.070312  5.593750  5.523438  0.336376      0           1  \n",
       "90   0.897866  0.007812  5.734375  5.726562  0.176654      0           1  \n",
       "167  1.106213  0.007812  4.421875  4.414062  0.230973      0           1  \n",
       "174  0.350507  0.007812  4.882812  4.875000  0.119712      0           1  \n",
       "175  0.280273  0.007812  4.453125  4.445312  0.107741      0           1  \n",
       "182  0.298573  0.031250  3.609375  3.578125  0.103764      0           1  \n",
       "183  0.242898  0.007812  5.492188  5.484375  0.052860      0           1  \n",
       "184  0.360625  0.023438  5.000000  4.976562  0.062794      0           1  \n",
       "215  0.698017  0.007812  5.703125  5.695312  0.139808      0           1  \n",
       "216  0.776278  0.007812  6.125000  6.117188  0.121208      0           1  \n",
       "323  0.916932  0.023438  3.656250  3.632812  0.147037      0           1  \n",
       "464  0.765244  0.007812  6.296875  6.289062  0.141246      0           1  \n",
       "591  0.188859  0.007812  0.757812  0.750000  0.250496      1           0  \n",
       "605  0.554957  0.007812  5.429688  5.421875  0.136785      1           0  \n",
       "882  0.276242  0.007812  1.070312  1.062500  0.237036      1           0  \n",
       "899  0.963949  0.043945  3.999023  3.955078  0.261785      1           0  \n",
       "900  0.498259  0.151367  1.425781  1.274414  0.447671      1           0  \n",
       "905  1.015625  0.004883  3.964844  3.959961  0.186095      1           0  \n",
       "\n",
       "[19 rows x 22 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = wrong_prediction\n",
    "\n",
    "new_table.iloc[indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 951 data, only 19 are not prediccted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - ROC Curve: \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - AUC: \n",
      " 0.9803367797541986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# print(f\"Test - Accuracy :  {accuracy_score(y_test, predictions)*100.0:.2f}%\")\n",
    "# print(\"Test - Classification Report: \\n\", metrics.classification_report(y_test, predictions))\n",
    "\n",
    "print(\"Test - ROC Curve: \\n\")\n",
    "fpr, tpr, thresholds = roc_curve(new_y, predictions)\n",
    "plt.plot([0,1], [0,1])\n",
    "plt.plot(fpr, tpr, label='TPOT')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('TPOT ROC curve')\n",
    "plt.show()\n",
    "\n",
    "print('Test - AUC: \\n', roc_auc_score(new_y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - Confusion Matrix: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Confusion Matrix'}, xlabel='Predicted label', ylabel='True label'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "import scikitplot as skplt\n",
    "\n",
    "print(\"Test - Confusion Matrix: \\n\")\n",
    "\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "skplt.metrics.plot_confusion_matrix(new_y, predictions,\n",
    "                                    title=\"Confusion Matrix\",\n",
    "                                    cmap=\"Oranges\",\n",
    "                                    ax=ax1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
