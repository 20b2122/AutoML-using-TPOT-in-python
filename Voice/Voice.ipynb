{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Automated ML Pipeline Generator using TPOT in Python\n",
    "---\n",
    "<br/>\n",
    "\n",
    "### What is TPOT?\n",
    "- Tree-Based Pipeline Optimization Tool (TPOT)\n",
    "- a tool that optimizes machine learning pipelines using genetic programming. \n",
    "- exploring thousands of possible pipelines to find the best one for your data. \n",
    "- Once TPOT is finished searching (or you get tired of waiting), it provides you with the Python code for the best pipeline it found so you can tinker with the pipeline from there. \n",
    "- TPOT makes use of the Python-based scikit-learn library as its ML menu.\n",
    "- pipeline is an independently executable workflow of a complete machine learning task.\n",
    "\n",
    "### To install :\n",
    "    pip install tpot\n",
    "\n",
    "### Dependencies :\n",
    "- scikit learn\n",
    "- numpy \n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data_url = \"https://raw.githubusercontent.com/20b2122/AutoML-using-TPOT-in-python/main/Voice/voice.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "0   274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
       "1   634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
       "2  1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
       "3     4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
       "4     4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
       "\n",
       "     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000   male  \n",
       "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632   male  \n",
       "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512   male  \n",
       "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119   male  \n",
       "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274   male  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "meanfreq    0\n",
       "sd          0\n",
       "median      0\n",
       "Q25         0\n",
       "Q75         0\n",
       "IQR         0\n",
       "skew        0\n",
       "kurt        0\n",
       "sp.ent      0\n",
       "sfm         0\n",
       "mode        0\n",
       "centroid    0\n",
       "meanfun     0\n",
       "minfun      0\n",
       "maxfun      0\n",
       "meandom     0\n",
       "mindom      0\n",
       "maxdom      0\n",
       "dfrange     0\n",
       "modindx     0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 21 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   meanfreq  3168 non-null   float64\n",
      " 1   sd        3168 non-null   float64\n",
      " 2   median    3168 non-null   float64\n",
      " 3   Q25       3168 non-null   float64\n",
      " 4   Q75       3168 non-null   float64\n",
      " 5   IQR       3168 non-null   float64\n",
      " 6   skew      3168 non-null   float64\n",
      " 7   kurt      3168 non-null   float64\n",
      " 8   sp.ent    3168 non-null   float64\n",
      " 9   sfm       3168 non-null   float64\n",
      " 10  mode      3168 non-null   float64\n",
      " 11  centroid  3168 non-null   float64\n",
      " 12  meanfun   3168 non-null   float64\n",
      " 13  minfun    3168 non-null   float64\n",
      " 14  maxfun    3168 non-null   float64\n",
      " 15  meandom   3168 non-null   float64\n",
      " 16  mindom    3168 non-null   float64\n",
      " 17  maxdom    3168 non-null   float64\n",
      " 18  dfrange   3168 non-null   float64\n",
      " 19  modindx   3168 non-null   float64\n",
      " 20  label     3168 non-null   object \n",
      "dtypes: float64(20), object(1)\n",
      "memory usage: 519.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convert Categorical (label) to Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['label'] = df['label'].map({'female': 1, 'male': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "0   274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
       "1   634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
       "2  1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
       "3     4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
       "4     4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
       "\n",
       "     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000      0  \n",
       "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632      0  \n",
       "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512      0  \n",
       "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119      0  \n",
       "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274      0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 21 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   meanfreq  3168 non-null   float64\n",
      " 1   sd        3168 non-null   float64\n",
      " 2   median    3168 non-null   float64\n",
      " 3   Q25       3168 non-null   float64\n",
      " 4   Q75       3168 non-null   float64\n",
      " 5   IQR       3168 non-null   float64\n",
      " 6   skew      3168 non-null   float64\n",
      " 7   kurt      3168 non-null   float64\n",
      " 8   sp.ent    3168 non-null   float64\n",
      " 9   sfm       3168 non-null   float64\n",
      " 10  mode      3168 non-null   float64\n",
      " 11  centroid  3168 non-null   float64\n",
      " 12  meanfun   3168 non-null   float64\n",
      " 13  minfun    3168 non-null   float64\n",
      " 14  maxfun    3168 non-null   float64\n",
      " 15  meandom   3168 non-null   float64\n",
      " 16  mindom    3168 non-null   float64\n",
      " 17  maxdom    3168 non-null   float64\n",
      " 18  dfrange   3168 non-null   float64\n",
      " 19  modindx   3168 non-null   float64\n",
      " 20  label     3168 non-null   int64  \n",
      "dtypes: float64(20), int64(1)\n",
      "memory usage: 519.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info() # double check if all of the categorical has been converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Splitting data into input and output (label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = df.iloc[:,:20] # input\n",
    "y = df.iloc[:,20:] # output - label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Algorithm - find the mean of the algorithm \n",
    "(Not related to TPOT - just for comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Machine Learning libraries\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(LogisticRegression(), x, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation values:\n",
      " [0.65930599 0.83911672 0.79495268 0.86435331 0.78233438 0.93375394\n",
      " 0.96214511 0.96214511 0.92088608 0.88607595]\n",
      "\n",
      "Mean of cross-validation: 0.8605069280836959\n"
     ]
    }
   ],
   "source": [
    "print(\"cross-validation values:\\n\", cv_scores)\n",
    "print(\"\\nMean of cross-validation:\", np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "rf_cv_scores = cross_val_score(RandomForestClassifier(), x, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest cross-validation values:\n",
      " [0.93690852 0.94637224 0.9873817  0.95899054 0.96529968 0.99369085\n",
      " 0.99369085 0.98422713 0.9335443  0.99367089]\n",
      "\n",
      "Mean of random forest cross-validation: 0.9693776704069001\n"
     ]
    }
   ],
   "source": [
    "print(\"Random forest cross-validation values:\\n\", rf_cv_scores)\n",
    "print(\"\\nMean of random forest cross-validation:\", np.mean(rf_cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\tpot\\builtins\\__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    }
   ],
   "source": [
    "import tpot\n",
    "import time # to calculate how long it takes for the TPOT to finish execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the available methods and attributes at TPOT\n",
    "\n",
    "Using this dataset, we will use TPOTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TPOTClassifier',\n",
       " 'TPOTRegressor',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " '_version',\n",
       " 'base',\n",
       " 'builtins',\n",
       " 'config',\n",
       " 'decorators',\n",
       " 'driver',\n",
       " 'export_utils',\n",
       " 'gp_deap',\n",
       " 'gp_types',\n",
       " 'main',\n",
       " 'metrics',\n",
       " 'operator_utils',\n",
       " 'tpot']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tpot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data in x and y into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "\n",
    "# Init\n",
    "tpot = TPOTClassifier(generations=5, population_size=50, verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generation**: Number of iterations to run the pipeline optimization process.TPOT will work better when you give it more generations (and therefore time) to optimize the pipeline. <br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Population Size**: Number of individuals to retain in the GP population every generation.<br/>\n",
    "<br/>\n",
    "TPOT will evaluate POPULATION_SIZE (50) + GENERATIONS (5) x OFFSPRING_SIZE (50) = 300 pipelines in total.\n",
    "<br/>\n",
    "By default, OFFSPRING_SIZE = POPULATION_SIZE<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verbosity**: How much information TPOT communicates while it is running. 0 = none, 1 = minimal, 2 = high, 3 = all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                               \n",
      "Generation 1 - Current best internal CV score: 0.9819565615276676\n",
      "                                                                                \n",
      "Generation 2 - Current best internal CV score: 0.9819575783458403\n",
      "                                                                              \n",
      "Generation 3 - Current best internal CV score: 0.9819575783458403\n",
      "                                                                              \n",
      "Generation 4 - Current best internal CV score: 0.9842118642344376\n",
      "                                                                              \n",
      "Generation 5 - Current best internal CV score: 0.9846612978667155\n",
      "                                                                              \n",
      "Best pipeline: GradientBoostingClassifier(input_matrix, learning_rate=0.5, max_depth=10, max_features=0.25, min_samples_leaf=14, min_samples_split=17, n_estimators=100, subsample=0.55)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Fit data\n",
    "tpot.fit(x_train, y_train)\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boosting Classifier**: a group of machine learning algorithms that combine many weak learning models together to create a strong predictive model. Decision trees are usually used when doing gradient boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "time: 1263.561945438385\n",
      "Mean Absolute Error: 0.022082018927444796\n",
      "Mean Squared Error: 0.022082018927444796\n",
      "Coef of Determination, R2: 0.9114556546721763\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "y_pred = tpot.predict(x_test)\n",
    "\n",
    "print('\\ntime:',(end-start))\n",
    "print('Mean Absolute Error:',mean_absolute_error(y_pred=y_pred, y_true=y_test))\n",
    "print('Mean Squared Error:',mean_squared_error(y_pred=y_pred, y_true=y_test))\n",
    "print('Coef of Determination, R2:',r2_score(y_pred=y_pred, y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MAE**: measures the average of the residuals in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MSE**: average of the squared difference between the original and predicted values in the data set. Measures the variance of the residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$R^{2}$**: represents the coefficient of how well the values fit compared to the original values. The value from 0 to 1 interpreted as percentages. The higher the value is, the better the model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the result\n",
    "tpot.export('TPOTClassifier_ml_pipeline.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The 'TPOTClassifier_ml_pipeline.py' file will contain the Python code for the optimized pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.ensemble</span> <span class=\"kn\">import</span> <span class=\"n\">GradientBoostingClassifier</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">train_test_split</span>\n",
       "\n",
       "<span class=\"c1\"># NOTE: Make sure that the outcome column is labeled &#39;target&#39; in the data file</span>\n",
       "<span class=\"n\">tpot_data</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s1\">&#39;PATH/TO/DATA/FILE&#39;</span><span class=\"p\">,</span> <span class=\"n\">sep</span><span class=\"o\">=</span><span class=\"s1\">&#39;COLUMN_SEPARATOR&#39;</span><span class=\"p\">,</span> <span class=\"kp\">dtype</span><span class=\"o\">=</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float64</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">features</span> <span class=\"o\">=</span> <span class=\"n\">tpot_data</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"s1\">&#39;target&#39;</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">training_features</span><span class=\"p\">,</span> <span class=\"n\">testing_features</span><span class=\"p\">,</span> <span class=\"n\">training_target</span><span class=\"p\">,</span> <span class=\"n\">testing_target</span> <span class=\"o\">=</span> \\\n",
       "            <span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">tpot_data</span><span class=\"p\">[</span><span class=\"s1\">&#39;target&#39;</span><span class=\"p\">],</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Average CV score on the training set was: 0.9846612978667155</span>\n",
       "<span class=\"n\">exported_pipeline</span> <span class=\"o\">=</span> <span class=\"n\">GradientBoostingClassifier</span><span class=\"p\">(</span><span class=\"n\">learning_rate</span><span class=\"o\">=</span><span class=\"mf\">0.5</span><span class=\"p\">,</span> <span class=\"n\">max_depth</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">max_features</span><span class=\"o\">=</span><span class=\"mf\">0.25</span><span class=\"p\">,</span> <span class=\"n\">min_samples_leaf</span><span class=\"o\">=</span><span class=\"mi\">14</span><span class=\"p\">,</span> <span class=\"n\">min_samples_split</span><span class=\"o\">=</span><span class=\"mi\">17</span><span class=\"p\">,</span> <span class=\"n\">n_estimators</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">subsample</span><span class=\"o\">=</span><span class=\"mf\">0.55</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"n\">exported_pipeline</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">training_features</span><span class=\"p\">,</span> <span class=\"n\">training_target</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"n\">exported_pipeline</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">testing_features</span><span class=\"p\">)</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{numpy} \\PY{k}{as} \\PY{n+nn}{np}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{pandas} \\PY{k}{as} \\PY{n+nn}{pd}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{ensemble} \\PY{k+kn}{import} \\PY{n}{GradientBoostingClassifier}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{model\\PYZus{}selection} \\PY{k+kn}{import} \\PY{n}{train\\PYZus{}test\\PYZus{}split}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} NOTE: Make sure that the outcome column is labeled \\PYZsq{}target\\PYZsq{} in the data file}\n",
       "\\PY{n}{tpot\\PYZus{}data} \\PY{o}{=} \\PY{n}{pd}\\PY{o}{.}\\PY{n}{read\\PYZus{}csv}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{PATH/TO/DATA/FILE}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{sep}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{COLUMN\\PYZus{}SEPARATOR}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{k+kp}{dtype}\\PY{o}{=}\\PY{n}{np}\\PY{o}{.}\\PY{n}{float64}\\PY{p}{)}\n",
       "\\PY{n}{features} \\PY{o}{=} \\PY{n}{tpot\\PYZus{}data}\\PY{o}{.}\\PY{n}{drop}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{target}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{)}\n",
       "\\PY{n}{training\\PYZus{}features}\\PY{p}{,} \\PY{n}{testing\\PYZus{}features}\\PY{p}{,} \\PY{n}{training\\PYZus{}target}\\PY{p}{,} \\PY{n}{testing\\PYZus{}target} \\PY{o}{=} \\PYZbs{}\n",
       "            \\PY{n}{train\\PYZus{}test\\PYZus{}split}\\PY{p}{(}\\PY{n}{features}\\PY{p}{,} \\PY{n}{tpot\\PYZus{}data}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{target}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{random\\PYZus{}state}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Average CV score on the training set was: 0.9846612978667155}\n",
       "\\PY{n}{exported\\PYZus{}pipeline} \\PY{o}{=} \\PY{n}{GradientBoostingClassifier}\\PY{p}{(}\\PY{n}{learning\\PYZus{}rate}\\PY{o}{=}\\PY{l+m+mf}{0.5}\\PY{p}{,} \\PY{n}{max\\PYZus{}depth}\\PY{o}{=}\\PY{l+m+mi}{10}\\PY{p}{,} \\PY{n}{max\\PYZus{}features}\\PY{o}{=}\\PY{l+m+mf}{0.25}\\PY{p}{,} \\PY{n}{min\\PYZus{}samples\\PYZus{}leaf}\\PY{o}{=}\\PY{l+m+mi}{14}\\PY{p}{,} \\PY{n}{min\\PYZus{}samples\\PYZus{}split}\\PY{o}{=}\\PY{l+m+mi}{17}\\PY{p}{,} \\PY{n}{n\\PYZus{}estimators}\\PY{o}{=}\\PY{l+m+mi}{100}\\PY{p}{,} \\PY{n}{subsample}\\PY{o}{=}\\PY{l+m+mf}{0.55}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{exported\\PYZus{}pipeline}\\PY{o}{.}\\PY{n}{fit}\\PY{p}{(}\\PY{n}{training\\PYZus{}features}\\PY{p}{,} \\PY{n}{training\\PYZus{}target}\\PY{p}{)}\n",
       "\\PY{n}{results} \\PY{o}{=} \\PY{n}{exported\\PYZus{}pipeline}\\PY{o}{.}\\PY{n}{predict}\\PY{p}{(}\\PY{n}{testing\\PYZus{}features}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "import numpy as np\n",
       "import pandas as pd\n",
       "from sklearn.ensemble import GradientBoostingClassifier\n",
       "from sklearn.model_selection import train_test_split\n",
       "\n",
       "# NOTE: Make sure that the outcome column is labeled 'target' in the data file\n",
       "tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\n",
       "features = tpot_data.drop('target', axis=1)\n",
       "training_features, testing_features, training_target, testing_target = \\\n",
       "            train_test_split(features, tpot_data['target'], random_state=None)\n",
       "\n",
       "# Average CV score on the training set was: 0.9846612978667155\n",
       "exported_pipeline = GradientBoostingClassifier(learning_rate=0.5, max_depth=10, max_features=0.25, min_samples_leaf=14, min_samples_split=17, n_estimators=100, subsample=0.55)\n",
       "\n",
       "exported_pipeline.fit(training_features, training_target)\n",
       "results = exported_pipeline.predict(testing_features)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.display.Code('https://raw.githubusercontent.com/20b2122/AutoML-using-TPOT-in-python/main/Voice/TPOTClassifier_ml_pipeline.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "- preparing the predicted(y_pred) data to be shown in a table with x_test and y_test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.160514</td>\n",
       "      <td>0.076767</td>\n",
       "      <td>0.144337</td>\n",
       "      <td>0.110532</td>\n",
       "      <td>0.231962</td>\n",
       "      <td>0.121430</td>\n",
       "      <td>1.397156</td>\n",
       "      <td>4.766611</td>\n",
       "      <td>0.959255</td>\n",
       "      <td>0.719858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093052</td>\n",
       "      <td>0.017758</td>\n",
       "      <td>0.144144</td>\n",
       "      <td>0.301339</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.283937</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.137343</td>\n",
       "      <td>0.080877</td>\n",
       "      <td>0.124263</td>\n",
       "      <td>0.083145</td>\n",
       "      <td>0.209227</td>\n",
       "      <td>0.126082</td>\n",
       "      <td>1.378728</td>\n",
       "      <td>5.008952</td>\n",
       "      <td>0.963514</td>\n",
       "      <td>0.736150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092644</td>\n",
       "      <td>0.016789</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.481671</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>5.015625</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.183115</td>\n",
       "      <td>0.066982</td>\n",
       "      <td>0.191233</td>\n",
       "      <td>0.129149</td>\n",
       "      <td>0.240152</td>\n",
       "      <td>0.111004</td>\n",
       "      <td>3.568104</td>\n",
       "      <td>35.384748</td>\n",
       "      <td>0.940333</td>\n",
       "      <td>0.571394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102799</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>1.245739</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>6.742188</td>\n",
       "      <td>6.539062</td>\n",
       "      <td>0.139332</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.171247</td>\n",
       "      <td>0.074872</td>\n",
       "      <td>0.152807</td>\n",
       "      <td>0.122391</td>\n",
       "      <td>0.243617</td>\n",
       "      <td>0.121227</td>\n",
       "      <td>3.207170</td>\n",
       "      <td>25.765565</td>\n",
       "      <td>0.936954</td>\n",
       "      <td>0.586420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079718</td>\n",
       "      <td>0.015671</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.106279</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.138355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>0.201806</td>\n",
       "      <td>0.036057</td>\n",
       "      <td>0.201622</td>\n",
       "      <td>0.178165</td>\n",
       "      <td>0.227872</td>\n",
       "      <td>0.049707</td>\n",
       "      <td>1.585353</td>\n",
       "      <td>4.945634</td>\n",
       "      <td>0.884731</td>\n",
       "      <td>0.227903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191704</td>\n",
       "      <td>0.032720</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.921875</td>\n",
       "      <td>5.914062</td>\n",
       "      <td>0.124383</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>0.183667</td>\n",
       "      <td>0.040607</td>\n",
       "      <td>0.182534</td>\n",
       "      <td>0.156480</td>\n",
       "      <td>0.207646</td>\n",
       "      <td>0.051166</td>\n",
       "      <td>2.054138</td>\n",
       "      <td>7.483019</td>\n",
       "      <td>0.898138</td>\n",
       "      <td>0.313925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149237</td>\n",
       "      <td>0.018648</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.550312</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>3.421875</td>\n",
       "      <td>3.414062</td>\n",
       "      <td>0.166503</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>0.131884</td>\n",
       "      <td>0.084734</td>\n",
       "      <td>0.153707</td>\n",
       "      <td>0.049285</td>\n",
       "      <td>0.201144</td>\n",
       "      <td>0.151859</td>\n",
       "      <td>1.762129</td>\n",
       "      <td>6.630383</td>\n",
       "      <td>0.962934</td>\n",
       "      <td>0.763182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182790</td>\n",
       "      <td>0.083770</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.832899</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.210938</td>\n",
       "      <td>4.203125</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>0.116221</td>\n",
       "      <td>0.089221</td>\n",
       "      <td>0.076758</td>\n",
       "      <td>0.042718</td>\n",
       "      <td>0.204911</td>\n",
       "      <td>0.162193</td>\n",
       "      <td>0.693730</td>\n",
       "      <td>2.503954</td>\n",
       "      <td>0.960716</td>\n",
       "      <td>0.709570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188980</td>\n",
       "      <td>0.034409</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.909856</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>3.679688</td>\n",
       "      <td>3.640625</td>\n",
       "      <td>0.277897</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.092884</td>\n",
       "      <td>0.183044</td>\n",
       "      <td>0.070072</td>\n",
       "      <td>0.250827</td>\n",
       "      <td>0.180756</td>\n",
       "      <td>1.705029</td>\n",
       "      <td>5.769115</td>\n",
       "      <td>0.938829</td>\n",
       "      <td>0.601529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185607</td>\n",
       "      <td>0.062257</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.227022</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>951 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0    0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1    0.160514  0.076767  0.144337  0.110532  0.231962  0.121430   1.397156   \n",
       "2    0.137343  0.080877  0.124263  0.083145  0.209227  0.126082   1.378728   \n",
       "3    0.183115  0.066982  0.191233  0.129149  0.240152  0.111004   3.568104   \n",
       "4    0.171247  0.074872  0.152807  0.122391  0.243617  0.121227   3.207170   \n",
       "..        ...       ...       ...       ...       ...       ...        ...   \n",
       "946  0.201806  0.036057  0.201622  0.178165  0.227872  0.049707   1.585353   \n",
       "947  0.183667  0.040607  0.182534  0.156480  0.207646  0.051166   2.054138   \n",
       "948  0.131884  0.084734  0.153707  0.049285  0.201144  0.151859   1.762129   \n",
       "949  0.116221  0.089221  0.076758  0.042718  0.204911  0.162193   0.693730   \n",
       "950  0.165509  0.092884  0.183044  0.070072  0.250827  0.180756   1.705029   \n",
       "\n",
       "           kurt    sp.ent       sfm  ...   meanfun    minfun    maxfun  \\\n",
       "0    274.402906  0.893369  0.491918  ...  0.084279  0.015702  0.275862   \n",
       "1      4.766611  0.959255  0.719858  ...  0.093052  0.017758  0.144144   \n",
       "2      5.008952  0.963514  0.736150  ...  0.092644  0.016789  0.213333   \n",
       "3     35.384748  0.940333  0.571394  ...  0.102799  0.020833  0.275862   \n",
       "4     25.765565  0.936954  0.586420  ...  0.079718  0.015671  0.262295   \n",
       "..          ...       ...       ...  ...       ...       ...       ...   \n",
       "946    4.945634  0.884731  0.227903  ...  0.191704  0.032720  0.275862   \n",
       "947    7.483019  0.898138  0.313925  ...  0.149237  0.018648  0.262295   \n",
       "948    6.630383  0.962934  0.763182  ...  0.182790  0.083770  0.262295   \n",
       "949    2.503954  0.960716  0.709570  ...  0.188980  0.034409  0.275862   \n",
       "950    5.769115  0.938829  0.601529  ...  0.185607  0.062257  0.271186   \n",
       "\n",
       "      meandom    mindom    maxdom   dfrange   modindx  label  pred_label  \n",
       "0    0.007812  0.007812  0.007812  0.000000  0.000000      0           0  \n",
       "1    0.301339  0.007812  0.539062  0.531250  0.283937      0           0  \n",
       "2    0.481671  0.015625  5.015625  5.000000  0.088500      0           0  \n",
       "3    1.245739  0.203125  6.742188  6.539062  0.139332      0           0  \n",
       "4    0.106279  0.007812  0.570312  0.562500  0.138355      0           0  \n",
       "..        ...       ...       ...       ...       ...    ...         ...  \n",
       "946  0.593750  0.007812  5.921875  5.914062  0.124383      1           1  \n",
       "947  0.550312  0.007812  3.421875  3.414062  0.166503      1           1  \n",
       "948  0.832899  0.007812  4.210938  4.203125  0.161929      1           1  \n",
       "949  0.909856  0.039062  3.679688  3.640625  0.277897      1           1  \n",
       "950  0.227022  0.007812  0.554688  0.546875  0.350000      1           1  \n",
       "\n",
       "[951 rows x 22 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to ensure one the tables are joined the data are aligned\n",
    "sort_x = x_test.sort_index()\n",
    "new_x = sort_x.reset_index().drop(columns=['index'])\n",
    "\n",
    "sort_y = y_test.sort_index()\n",
    "new_y = sort_y.reset_index().drop(columns=['index'])\n",
    "\n",
    "# converting the array into list then into a table\n",
    "y_pred = tpot.predict(new_x).tolist() \n",
    "predictions = pd.DataFrame({ 'pred_label':y_pred }) \n",
    "\n",
    "new_table = pd.concat([new_x, new_y, predictions], axis=1)\n",
    "new_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test sample wrongly predicte: 21\n"
     ]
    }
   ],
   "source": [
    "wrong_prediction = np.where(new_table['label'] != new_table['pred_label'])[0]\n",
    "print(\"Total number of test sample wrongly predicte:\",len(wrong_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.167334</td>\n",
       "      <td>0.047178</td>\n",
       "      <td>0.161802</td>\n",
       "      <td>0.135475</td>\n",
       "      <td>0.180725</td>\n",
       "      <td>0.045250</td>\n",
       "      <td>3.961908</td>\n",
       "      <td>24.419622</td>\n",
       "      <td>0.880375</td>\n",
       "      <td>0.344307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.016032</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>6.921875</td>\n",
       "      <td>6.796875</td>\n",
       "      <td>0.021648</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.200830</td>\n",
       "      <td>0.053066</td>\n",
       "      <td>0.210059</td>\n",
       "      <td>0.185332</td>\n",
       "      <td>0.236198</td>\n",
       "      <td>0.050866</td>\n",
       "      <td>1.840901</td>\n",
       "      <td>6.006801</td>\n",
       "      <td>0.907683</td>\n",
       "      <td>0.386818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165155</td>\n",
       "      <td>0.015764</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>1.067057</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>5.593750</td>\n",
       "      <td>5.523438</td>\n",
       "      <td>0.336376</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.224382</td>\n",
       "      <td>0.048547</td>\n",
       "      <td>0.240617</td>\n",
       "      <td>0.220672</td>\n",
       "      <td>0.255481</td>\n",
       "      <td>0.034809</td>\n",
       "      <td>3.095413</td>\n",
       "      <td>15.076874</td>\n",
       "      <td>0.858363</td>\n",
       "      <td>0.130449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138002</td>\n",
       "      <td>0.031873</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.897866</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.734375</td>\n",
       "      <td>5.726562</td>\n",
       "      <td>0.176654</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.138336</td>\n",
       "      <td>0.085693</td>\n",
       "      <td>0.126748</td>\n",
       "      <td>0.060881</td>\n",
       "      <td>0.238669</td>\n",
       "      <td>0.177788</td>\n",
       "      <td>2.668286</td>\n",
       "      <td>13.514607</td>\n",
       "      <td>0.943047</td>\n",
       "      <td>0.611900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138233</td>\n",
       "      <td>0.016360</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>1.106213</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.421875</td>\n",
       "      <td>4.414062</td>\n",
       "      <td>0.230973</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.160468</td>\n",
       "      <td>0.077851</td>\n",
       "      <td>0.149529</td>\n",
       "      <td>0.125194</td>\n",
       "      <td>0.239979</td>\n",
       "      <td>0.114785</td>\n",
       "      <td>2.907550</td>\n",
       "      <td>19.862833</td>\n",
       "      <td>0.940861</td>\n",
       "      <td>0.610161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141772</td>\n",
       "      <td>0.016967</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.350507</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.882812</td>\n",
       "      <td>4.875000</td>\n",
       "      <td>0.119712</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.137655</td>\n",
       "      <td>0.084477</td>\n",
       "      <td>0.133981</td>\n",
       "      <td>0.072697</td>\n",
       "      <td>0.222624</td>\n",
       "      <td>0.149927</td>\n",
       "      <td>3.999052</td>\n",
       "      <td>42.125516</td>\n",
       "      <td>0.933738</td>\n",
       "      <td>0.575355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148467</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.280273</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.453125</td>\n",
       "      <td>4.445312</td>\n",
       "      <td>0.107741</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.129003</td>\n",
       "      <td>0.070466</td>\n",
       "      <td>0.134949</td>\n",
       "      <td>0.070524</td>\n",
       "      <td>0.170783</td>\n",
       "      <td>0.100259</td>\n",
       "      <td>1.298188</td>\n",
       "      <td>4.588312</td>\n",
       "      <td>0.964036</td>\n",
       "      <td>0.727164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139353</td>\n",
       "      <td>0.019208</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.298573</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>3.609375</td>\n",
       "      <td>3.578125</td>\n",
       "      <td>0.103764</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.125830</td>\n",
       "      <td>0.077782</td>\n",
       "      <td>0.128703</td>\n",
       "      <td>0.055812</td>\n",
       "      <td>0.170730</td>\n",
       "      <td>0.114918</td>\n",
       "      <td>1.330019</td>\n",
       "      <td>5.444218</td>\n",
       "      <td>0.967389</td>\n",
       "      <td>0.712792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136684</td>\n",
       "      <td>0.015810</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.242898</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.492188</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>0.052860</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.145676</td>\n",
       "      <td>0.066909</td>\n",
       "      <td>0.145363</td>\n",
       "      <td>0.116707</td>\n",
       "      <td>0.172739</td>\n",
       "      <td>0.056032</td>\n",
       "      <td>1.928249</td>\n",
       "      <td>6.910776</td>\n",
       "      <td>0.935388</td>\n",
       "      <td>0.564341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120921</td>\n",
       "      <td>0.015764</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.360625</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.976562</td>\n",
       "      <td>0.062794</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.092579</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>0.066576</td>\n",
       "      <td>0.016433</td>\n",
       "      <td>0.166652</td>\n",
       "      <td>0.150218</td>\n",
       "      <td>3.570619</td>\n",
       "      <td>19.677106</td>\n",
       "      <td>0.931496</td>\n",
       "      <td>0.617675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160002</td>\n",
       "      <td>0.021080</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>0.698017</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.703125</td>\n",
       "      <td>5.695312</td>\n",
       "      <td>0.139808</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.091436</td>\n",
       "      <td>0.077062</td>\n",
       "      <td>0.070372</td>\n",
       "      <td>0.023457</td>\n",
       "      <td>0.153963</td>\n",
       "      <td>0.130505</td>\n",
       "      <td>2.354569</td>\n",
       "      <td>9.180173</td>\n",
       "      <td>0.956468</td>\n",
       "      <td>0.731009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161466</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>0.776278</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>6.117188</td>\n",
       "      <td>0.121208</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0.151463</td>\n",
       "      <td>0.067562</td>\n",
       "      <td>0.175596</td>\n",
       "      <td>0.105085</td>\n",
       "      <td>0.197226</td>\n",
       "      <td>0.092141</td>\n",
       "      <td>2.303377</td>\n",
       "      <td>8.258878</td>\n",
       "      <td>0.932010</td>\n",
       "      <td>0.594163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177770</td>\n",
       "      <td>0.018370</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>1.411458</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>6.117188</td>\n",
       "      <td>0.277101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.183465</td>\n",
       "      <td>0.074338</td>\n",
       "      <td>0.189103</td>\n",
       "      <td>0.129266</td>\n",
       "      <td>0.253964</td>\n",
       "      <td>0.124698</td>\n",
       "      <td>1.710739</td>\n",
       "      <td>5.770098</td>\n",
       "      <td>0.945124</td>\n",
       "      <td>0.630813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154437</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.269663</td>\n",
       "      <td>0.927689</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>5.320312</td>\n",
       "      <td>5.296875</td>\n",
       "      <td>0.144271</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>0.176335</td>\n",
       "      <td>0.060897</td>\n",
       "      <td>0.168465</td>\n",
       "      <td>0.149488</td>\n",
       "      <td>0.224232</td>\n",
       "      <td>0.074744</td>\n",
       "      <td>2.357491</td>\n",
       "      <td>10.318722</td>\n",
       "      <td>0.922532</td>\n",
       "      <td>0.528765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136946</td>\n",
       "      <td>0.047809</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.916932</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>3.656250</td>\n",
       "      <td>3.632812</td>\n",
       "      <td>0.147037</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.191005</td>\n",
       "      <td>0.051353</td>\n",
       "      <td>0.173932</td>\n",
       "      <td>0.153824</td>\n",
       "      <td>0.244811</td>\n",
       "      <td>0.090987</td>\n",
       "      <td>1.508234</td>\n",
       "      <td>5.010486</td>\n",
       "      <td>0.890634</td>\n",
       "      <td>0.270410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138551</td>\n",
       "      <td>0.047572</td>\n",
       "      <td>0.274286</td>\n",
       "      <td>1.381669</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>8.859375</td>\n",
       "      <td>8.671875</td>\n",
       "      <td>0.139085</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>0.147858</td>\n",
       "      <td>0.078368</td>\n",
       "      <td>0.142228</td>\n",
       "      <td>0.122270</td>\n",
       "      <td>0.195709</td>\n",
       "      <td>0.073439</td>\n",
       "      <td>2.450805</td>\n",
       "      <td>10.017586</td>\n",
       "      <td>0.922367</td>\n",
       "      <td>0.545209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134173</td>\n",
       "      <td>0.019070</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.161979</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.175163</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0.173372</td>\n",
       "      <td>0.073989</td>\n",
       "      <td>0.190638</td>\n",
       "      <td>0.131436</td>\n",
       "      <td>0.228617</td>\n",
       "      <td>0.097181</td>\n",
       "      <td>1.908471</td>\n",
       "      <td>7.353245</td>\n",
       "      <td>0.943016</td>\n",
       "      <td>0.610966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112939</td>\n",
       "      <td>0.016343</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.276242</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>1.070312</td>\n",
       "      <td>1.062500</td>\n",
       "      <td>0.237036</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>0.179889</td>\n",
       "      <td>0.067810</td>\n",
       "      <td>0.163096</td>\n",
       "      <td>0.137244</td>\n",
       "      <td>0.246925</td>\n",
       "      <td>0.109681</td>\n",
       "      <td>2.106748</td>\n",
       "      <td>8.030296</td>\n",
       "      <td>0.932428</td>\n",
       "      <td>0.551025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136662</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.963949</td>\n",
       "      <td>0.043945</td>\n",
       "      <td>3.999023</td>\n",
       "      <td>3.955078</td>\n",
       "      <td>0.261785</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>0.177548</td>\n",
       "      <td>0.064797</td>\n",
       "      <td>0.168178</td>\n",
       "      <td>0.140357</td>\n",
       "      <td>0.236662</td>\n",
       "      <td>0.096306</td>\n",
       "      <td>1.506238</td>\n",
       "      <td>5.026300</td>\n",
       "      <td>0.942621</td>\n",
       "      <td>0.586907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127532</td>\n",
       "      <td>0.014815</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>1.015625</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>3.964844</td>\n",
       "      <td>3.959961</td>\n",
       "      <td>0.186095</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>0.082404</td>\n",
       "      <td>0.085136</td>\n",
       "      <td>0.035114</td>\n",
       "      <td>0.016920</td>\n",
       "      <td>0.152827</td>\n",
       "      <td>0.135906</td>\n",
       "      <td>2.570944</td>\n",
       "      <td>9.179264</td>\n",
       "      <td>0.921649</td>\n",
       "      <td>0.576089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183387</td>\n",
       "      <td>0.034043</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.328962</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>0.445053</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     meanfreq        sd    median       Q25       Q75       IQR      skew  \\\n",
       "20   0.167334  0.047178  0.161802  0.135475  0.180725  0.045250  3.961908   \n",
       "23   0.200830  0.053066  0.210059  0.185332  0.236198  0.050866  1.840901   \n",
       "90   0.224382  0.048547  0.240617  0.220672  0.255481  0.034809  3.095413   \n",
       "167  0.138336  0.085693  0.126748  0.060881  0.238669  0.177788  2.668286   \n",
       "174  0.160468  0.077851  0.149529  0.125194  0.239979  0.114785  2.907550   \n",
       "175  0.137655  0.084477  0.133981  0.072697  0.222624  0.149927  3.999052   \n",
       "182  0.129003  0.070466  0.134949  0.070524  0.170783  0.100259  1.298188   \n",
       "183  0.125830  0.077782  0.128703  0.055812  0.170730  0.114918  1.330019   \n",
       "184  0.145676  0.066909  0.145363  0.116707  0.172739  0.056032  1.928249   \n",
       "215  0.092579  0.080289  0.066576  0.016433  0.166652  0.150218  3.570619   \n",
       "216  0.091436  0.077062  0.070372  0.023457  0.153963  0.130505  2.354569   \n",
       "217  0.151463  0.067562  0.175596  0.105085  0.197226  0.092141  2.303377   \n",
       "286  0.183465  0.074338  0.189103  0.129266  0.253964  0.124698  1.710739   \n",
       "323  0.176335  0.060897  0.168465  0.149488  0.224232  0.074744  2.357491   \n",
       "437  0.191005  0.051353  0.173932  0.153824  0.244811  0.090987  1.508234   \n",
       "528  0.147858  0.078368  0.142228  0.122270  0.195709  0.073439  2.450805   \n",
       "882  0.173372  0.073989  0.190638  0.131436  0.228617  0.097181  1.908471   \n",
       "899  0.179889  0.067810  0.163096  0.137244  0.246925  0.109681  2.106748   \n",
       "905  0.177548  0.064797  0.168178  0.140357  0.236662  0.096306  1.506238   \n",
       "943  0.082404  0.085136  0.035114  0.016920  0.152827  0.135906  2.570944   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...   meanfun    minfun    maxfun  \\\n",
       "20   24.419622  0.880375  0.344307  ...  0.141810  0.016032  0.253968   \n",
       "23    6.006801  0.907683  0.386818  ...  0.165155  0.015764  0.271186   \n",
       "90   15.076874  0.858363  0.130449  ...  0.138002  0.031873  0.275862   \n",
       "167  13.514607  0.943047  0.611900  ...  0.138233  0.016360  0.275862   \n",
       "174  19.862833  0.940861  0.610161  ...  0.141772  0.016967  0.266667   \n",
       "175  42.125516  0.933738  0.575355  ...  0.148467  0.039216  0.271186   \n",
       "182   4.588312  0.964036  0.727164  ...  0.139353  0.019208  0.228571   \n",
       "183   5.444218  0.967389  0.712792  ...  0.136684  0.015810  0.275862   \n",
       "184   6.910776  0.935388  0.564341  ...  0.120921  0.015764  0.205128   \n",
       "215  19.677106  0.931496  0.617675  ...  0.160002  0.021080  0.246154   \n",
       "216   9.180173  0.956468  0.731009  ...  0.161466  0.016529  0.246154   \n",
       "217   8.258878  0.932010  0.594163  ...  0.177770  0.018370  0.262295   \n",
       "286   5.770098  0.945124  0.630813  ...  0.154437  0.047619  0.269663   \n",
       "323  10.318722  0.922532  0.528765  ...  0.136946  0.047809  0.275862   \n",
       "437   5.010486  0.890634  0.270410  ...  0.138551  0.047572  0.274286   \n",
       "528  10.017586  0.922367  0.545209  ...  0.134173  0.019070  0.262295   \n",
       "882   7.353245  0.943016  0.610966  ...  0.112939  0.016343  0.271186   \n",
       "899   8.030296  0.932428  0.551025  ...  0.136662  0.033898  0.277778   \n",
       "905   5.026300  0.942621  0.586907  ...  0.127532  0.014815  0.256410   \n",
       "943   9.179264  0.921649  0.576089  ...  0.183387  0.034043  0.275862   \n",
       "\n",
       "      meandom    mindom    maxdom   dfrange   modindx  label  pred_label  \n",
       "20   0.578125  0.125000  6.921875  6.796875  0.021648      0           1  \n",
       "23   1.067057  0.070312  5.593750  5.523438  0.336376      0           1  \n",
       "90   0.897866  0.007812  5.734375  5.726562  0.176654      0           1  \n",
       "167  1.106213  0.007812  4.421875  4.414062  0.230973      0           0  \n",
       "174  0.350507  0.007812  4.882812  4.875000  0.119712      0           1  \n",
       "175  0.280273  0.007812  4.453125  4.445312  0.107741      0           1  \n",
       "182  0.298573  0.031250  3.609375  3.578125  0.103764      0           1  \n",
       "183  0.242898  0.007812  5.492188  5.484375  0.052860      0           1  \n",
       "184  0.360625  0.023438  5.000000  4.976562  0.062794      0           1  \n",
       "215  0.698017  0.007812  5.703125  5.695312  0.139808      0           1  \n",
       "216  0.776278  0.007812  6.125000  6.117188  0.121208      0           1  \n",
       "217  1.411458  0.007812  6.125000  6.117188  0.277101      0           1  \n",
       "286  0.927689  0.023438  5.320312  5.296875  0.144271      0           1  \n",
       "323  0.916932  0.023438  3.656250  3.632812  0.147037      0           1  \n",
       "437  1.381669  0.187500  8.859375  8.671875  0.139085      0           1  \n",
       "528  0.161979  0.007812  0.671875  0.664062  0.175163      1           1  \n",
       "882  0.276242  0.007812  1.070312  1.062500  0.237036      1           0  \n",
       "899  0.963949  0.043945  3.999023  3.955078  0.261785      1           0  \n",
       "905  1.015625  0.004883  3.964844  3.959961  0.186095      1           0  \n",
       "943  0.328962  0.007812  0.750000  0.742188  0.445053      1           1  \n",
       "\n",
       "[20 rows x 22 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = [ 20,  23,  90, 167, 174, 175, 182, 183, 184, 215, 216, 217, 286, 323, 437, 528, 882, 899, 905, 943]\n",
    "\n",
    "actual_label = new_table['label']\n",
    "print([actual_label[x] for x in indexes])\n",
    "\n",
    "predicted_label = new_table['pred_label']\n",
    "print([predicted_label[x] for x in indexes])\n",
    "\n",
    "new_table.iloc[indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all of the predicted label are predicted correctly, except for 20 samples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
